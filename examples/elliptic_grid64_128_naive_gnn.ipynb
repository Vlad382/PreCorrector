{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15286633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '.95'\n",
    "sys.path.append('/mnt/local/data/vtrifonov/prec-learning-Notay-loss/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aa015a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import optax\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from utils import grid_script\n",
    "from config import default_naive_gnn_config\n",
    "from experiments.script_gnn_prec import script_gnn_prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebd520fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "path = '/mnt/local/data/vtrifonov/prec-learning-Notay-loss/'\n",
    "folder = 'results_cases/29.01_elliptic_grid64_128_naive_gnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93d3b113",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = {\n",
    "    'data_dir': path,\n",
    "    'pde': np.nan,\n",
    "    'grid': np.nan,\n",
    "    'variance': np.nan,\n",
    "    'lhs_type': np.nan,\n",
    "    'N_samples_train': 1000,\n",
    "    'N_samples_test': 200,\n",
    "    'fill_factor': 1,\n",
    "    'threshold': 1e-4\n",
    "}\n",
    "\n",
    "train_config = {\n",
    "    'model_type': 'naive_gnn',\n",
    "    'loss_type': np.nan,\n",
    "    'batch_size': 8,\n",
    "    'optimizer': optax.adam,\n",
    "    'lr': 1e-3,\n",
    "    'optim_params': {},\n",
    "    'epoch_num': 700\n",
    "}\n",
    "\n",
    "base_config = {\n",
    "    'path': path,\n",
    "    'folder_model': folder,\n",
    "    'folder_log': folder,\n",
    "    'name': np.nan,\n",
    "    'model_use': np.nan,\n",
    "    'save_model': True,\n",
    "    'cg_maxiter': np.nan,\n",
    "    'cg_atol': np.nan,\n",
    "    'data_config': data_config,\n",
    "    'model_config': default_naive_gnn_config,\n",
    "    'train_config': train_config,\n",
    "    'seed': seed\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1788cf6",
   "metadata": {},
   "source": [
    "# Div-k-grad, 64x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ae9e7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 03:08:46.241943: W external/xla/xla/service/gpu/nvptx_compiler.cc:760] The NVIDIA driver's CUDA version is 12.4 which is older than the ptxas CUDA version (12.5.40). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n",
      "[INFO | root | 2025-01-30 03:08:46] - %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "[INFO | root | 2025-01-30 03:08:46] - [GNN precs] script `6mmfo8` started execution.\n",
      "[INFO | root | 2025-01-30 03:08:46] - Config: {'path': '/mnt/local/data/vtrifonov/prec-learning-Notay-loss/', 'folder_model': 'results_cases/29.01_elliptic_grid64_128_naive_gnn', 'folder_log': 'results_cases/29.01_elliptic_grid64_128_naive_gnn', 'name': '6mmfo8', 'model_use': 'train', 'save_model': True, 'cg_maxiter': 500, 'cg_atol': 1e-12, 'data_config': {'data_dir': '/mnt/local/data/vtrifonov/prec-learning-Notay-loss/', 'pde': 'div_k_grad', 'grid': 32, 'variance': 0.1, 'lhs_type': 'fd', 'N_samples_train': 1000, 'N_samples_test': 200, 'fill_factor': 1, 'threshold': 0.0001}, 'model_config': {'layer_type': 'ConstantConv1d', 'node_enc': {'features': [1, 16, 16], 'N_layers': 2}, 'edge_enc': {'features': [1, 16, 16], 'N_layers': 2}, 'edge_dec': {'features': [16, 16, 1], 'N_layers': 2}, 'mp': {'edge_upd': {'features': [48, 16, 16], 'N_layers': 2}, 'node_upd': {'features': [32, 16, 16], 'N_layers': 2}, 'mp_rounds': 5, 'aggregate_edges': 'sum'}}, 'train_config': {'model_type': 'naive_gnn', 'loss_type': 'low_freq_loss', 'batch_size': 8, 'optimizer': <function adam at 0x7fb3a901e9e0>, 'lr': 0.001, 'optim_params': {}, 'epoch_num': 700}, 'seed': 42}.\n",
      "\n",
      "[INFO | root | 2025-01-30 03:08:47] - Data is loaded in 6.603e-01 sec.\n",
      "\n",
      "[WARNING | root | 2025-01-30 03:08:52] - /usr/local/lib/python3.10/dist-packages/jax/_src/lax/lax.py:2481: RuntimeWarning: invalid value encountered in cast\n",
      "  out = np.array(c).astype(eqn.params['new_dtype'])\n",
      "\n",
      "[WARNING | root | 2025-01-30 03:08:52] - /usr/local/lib/python3.10/dist-packages/jax/_src/lax/lax.py:2481: RuntimeWarning: invalid value encountered in cast\n",
      "  out = np.array(c).astype(eqn.params['new_dtype'])\n",
      "\n",
      "[WARNING | root | 2025-01-30 03:08:53] - /usr/local/lib/python3.10/dist-packages/jax/_src/lax/lax.py:2481: RuntimeWarning: invalid value encountered in cast\n",
      "  out = np.array(c).astype(eqn.params['new_dtype'])\n",
      "\n",
      "[WARNING | root | 2025-01-30 03:08:53] - /usr/local/lib/python3.10/dist-packages/jax/_src/lax/lax.py:2481: RuntimeWarning: invalid value encountered in cast\n",
      "  out = np.array(c).astype(eqn.params['new_dtype'])\n",
      "\n",
      "[INFO | root | 2025-01-30 03:14:24] - Model is trained in 3.367e+02 sec.\n",
      "[INFO | root | 2025-01-30 03:14:24] - PreCorrector's alpha = -.\n",
      "[INFO | root | 2025-01-30 03:14:24] - First and last losses: train = [8.760e+04, 9.065e+02], test = [8.604e+04, 9.556e+02].\n",
      "\n",
      "[WARNING | root | 2025-01-30 03:14:25] - /usr/local/lib/python3.10/dist-packages/jax/_src/lax/lax.py:2481: RuntimeWarning: invalid value encountered in cast\n",
      "  out = np.array(c).astype(eqn.params['new_dtype'])\n",
      "\n",
      "[WARNING | root | 2025-01-30 03:14:25] - /usr/local/lib/python3.10/dist-packages/jax/_src/lax/lax.py:2481: RuntimeWarning: invalid value encountered in cast\n",
      "  out = np.array(c).astype(eqn.params['new_dtype'])\n",
      "\n",
      "[WARNING | root | 2025-01-30 03:14:31] - /usr/local/lib/python3.10/dist-packages/jax/_src/lax/lax.py:2481: RuntimeWarning: invalid value encountered in cast\n",
      "  out = np.array(c).astype(eqn.params['new_dtype'])\n",
      "\n",
      "[INFO | root | 2025-01-30 03:14:34] - Precs are combined:\n",
      "[INFO | root | 2025-01-30 03:14:34] -  GNN prec construction time (sec) : mean = 3.074e-04, std = 4.264e-05.\n",
      "\n",
      "[INFO | root | 2025-01-30 03:15:06] - CG with GNN is finished:\n",
      "[INFO | root | 2025-01-30 03:15:07] -  iterations to atol([mean, std]): {0.001: [61.2, 5.85], 1e-06: [79.9, 7.42], 1e-09: [97.1, 9.22], 1e-12: [114.0, 10.84]};\n",
      "[INFO | root | 2025-01-30 03:15:07] -  time to atol([mean, std]): {0.001: [0.0812, 0.00768], 1e-06: [0.1056, 0.00974], 1e-09: [0.1281, 0.01206], 1e-12: [0.1501, 0.01418]};\n",
      "[INFO | root | 2025-01-30 03:15:07] -  number of linsystems for which CG did not conerge to atol: {0.001: 0, 1e-06: 0, 1e-09: 0, 1e-12: 0}.\n",
      "\n",
      "[INFO | root | 2025-01-30 03:15:07] - [GNN precs] script `6mmfo8` finished execution.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params_grid = ParameterGrid({\n",
    "    'model_use': ['train'],\n",
    "    'cg_maxiter': [500],\n",
    "    'cg_atol': [1e-12],\n",
    "    'model_type': ['naive_gnn'],\n",
    "    'loss_type': ['low_freq_loss'],\n",
    "    'batch_size': [8],\n",
    "    'lr': [1e-3],\n",
    "    'epoch_num': [700],\n",
    "    'pde': ['div_k_grad'],\n",
    "    'grid': [32],\n",
    "    'variance': [.1],#, .5, .7],\n",
    "    'lhs_type': ['fd'],\n",
    "    'fill_factor': [1],\n",
    "    'threshold': [1e-4]\n",
    "})\n",
    "\n",
    "grid_script(script_gnn_prec, base_config, params_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb64fc64",
   "metadata": {},
   "source": [
    "# Poisson, 64x64, 128x128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "076d9646",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 00:17:55.542245: W external/xla/xla/service/gpu/nvptx_compiler.cc:760] The NVIDIA driver's CUDA version is 12.4 which is older than the ptxas CUDA version (12.5.40). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n",
      "[INFO | root | 2025-01-31 00:17:56] - %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "[INFO | root | 2025-01-31 00:17:56] - [GNN precs] script `b3agaq` started execution.\n",
      "[INFO | root | 2025-01-31 00:17:56] - Config: {'path': '/mnt/local/data/vtrifonov/prec-learning-Notay-loss/', 'folder_model': 'results_cases/29.01_elliptic_grid64_128_naive_gnn', 'folder_log': 'results_cases/29.01_elliptic_grid64_128_naive_gnn', 'name': 'b3agaq', 'model_use': 'inference', 'save_model': True, 'cg_maxiter': 500, 'cg_atol': 1e-12, 'data_config': {'data_dir': '/mnt/local/data/vtrifonov/prec-learning-Notay-loss/', 'pde': 'poisson', 'grid': 128, 'variance': 0.5, 'lhs_type': 'fd', 'N_samples_train': 1000, 'N_samples_test': 200, 'fill_factor': 1, 'threshold': 0.0001}, 'model_config': {'layer_type': 'ConstantConv1d', 'node_enc': {'features': [1, 16, 16], 'N_layers': 2}, 'edge_enc': {'features': [1, 16, 16], 'N_layers': 2}, 'edge_dec': {'features': [16, 16, 1], 'N_layers': 2}, 'mp': {'edge_upd': {'features': [48, 16, 16], 'N_layers': 2}, 'node_upd': {'features': [32, 16, 16], 'N_layers': 2}, 'mp_rounds': 5, 'aggregate_edges': 'sum'}}, 'train_config': {'model_type': 'naive_gnn', 'loss_type': 'low_freq_loss', 'batch_size': 8, 'optimizer': <function adam at 0x7f81d551e710>, 'lr': 0.001, 'optim_params': {}, 'epoch_num': 2500}, 'seed': 42}.\n",
      "\n",
      "[INFO | root | 2025-01-31 00:17:57] - Data is loaded in 1.021e+00 sec.\n",
      "\n",
      "[CRITICAL | root | 2025-01-31 00:17:59] - Script failed on model training.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/local/data/vtrifonov/prec-learning-Notay-loss/experiments/script_gnn_prec.py\", line 87, in script_gnn_prec\n",
      "    model, losses, _ = train_inference_finetune(key, data, model_config, train_config, model_path=model_file,\n",
      "  File \"/mnt/local/data/vtrifonov/prec-learning-Notay-loss/train.py\", line 30, in train_inference_finetune\n",
      "    model, model_config = load_hp_and_model(model_path, make_model)\n",
      "  File \"/mnt/local/data/vtrifonov/prec-learning-Notay-loss/train.py\", line 214, in load_hp_and_model\n",
      "    with open(filename, \"rb\") as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/mnt/local/data/vtrifonov/prec-learning-Notay-loss/results_cases/29.01_elliptic_grid64_128_naive_gnn/b3agaq/b3agaq.eqx'\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 18\u001b[0m\n\u001b[1;32m      1\u001b[0m params_grid \u001b[38;5;241m=\u001b[39m ParameterGrid({\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_use\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minference\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcg_maxiter\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m500\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthreshold\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1e-4\u001b[39m]\n\u001b[1;32m     16\u001b[0m })\n\u001b[0;32m---> 18\u001b[0m \u001b[43mgrid_script\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscript_gnn_prec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams_grid\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/local/data/vtrifonov/prec-learning-Notay-loss/utils.py:34\u001b[0m, in \u001b[0;36mgrid_script\u001b[0;34m(script, base_config, params_grid)\u001b[0m\n\u001b[1;32m     31\u001b[0m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m     33\u001b[0m out \u001b[38;5;241m=\u001b[39m script(config, return_meta_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     35\u001b[0m     meta_data_df\u001b[38;5;241m.\u001b[39mloc[config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m], k] \u001b[38;5;241m=\u001b[39m v\n\u001b[1;32m     36\u001b[0m meta_data_df\u001b[38;5;241m.\u001b[39mto_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(meta_data_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeta_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'bool' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "params_grid = ParameterGrid({\n",
    "    'model_use': ['train'],\n",
    "    'cg_maxiter': [500],\n",
    "    'cg_atol': [1e-12],\n",
    "    'model_type': ['naive_gnn'],\n",
    "    'loss_type': ['low_freq_loss'],\n",
    "    'batch_size': [8],\n",
    "    'lr': [1e-3],\n",
    "    'epoch_num': [2500],\n",
    "    'pde': ['poisson'],\n",
    "    'grid': [128],\n",
    "    'variance': [.5],\n",
    "    'lhs_type': ['fd'],\n",
    "    'fill_factor': [1],\n",
    "    'threshold': [1e-4]\n",
    "})\n",
    "\n",
    "grid_script(script_gnn_prec, base_config, params_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414069dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2330a636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aed6b6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/mnt/local/data/vtrifonov/prec-learning-Notay-loss/'\n",
    "data_config = {\n",
    "    'data_dir': path,\n",
    "    'pde': 'poisson',\n",
    "    'grid': 128,\n",
    "    'variance': .5,\n",
    "    'lhs_type': 'fd',\n",
    "    'N_samples_train': np.nan,\n",
    "    'N_samples_test': 200,\n",
    "    'fill_factor': np.nan,\n",
    "    'threshold': np.nan\n",
    "}\n",
    "\n",
    "train_config = {\n",
    "    'model_type': 'naive_gnn',\n",
    "    'loss_type': np.nan,\n",
    "    'batch_size': 8,\n",
    "    'optimizer': optax.adam,\n",
    "    'lr': 1e-3,\n",
    "    'optim_params': {},\n",
    "    'epoch_num': 700\n",
    "}\n",
    "\n",
    "config = {\n",
    "    'path': path,\n",
    "    'folder_model': folder,\n",
    "    'folder_log': folder,\n",
    "    'name': 'edbpd1',\n",
    "    'model_use': 'inference',\n",
    "    'save_model': False,\n",
    "    'cg_maxiter': 500,\n",
    "    'cg_atol': 1e-12,\n",
    "    'data_config': data_config,\n",
    "    'model_config': default_naive_gnn_config,\n",
    "    'train_config': train_config,\n",
    "    'seed': seed\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88436cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO | root | 2025-01-31 00:27:07] - %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "[INFO | root | 2025-01-31 00:27:07] - [GNN precs] script `edbpd1` started execution.\n",
      "[INFO | root | 2025-01-31 00:27:07] - Config: {'path': '/mnt/local/data/vtrifonov/prec-learning-Notay-loss/', 'folder_model': 'results_cases/29.01_elliptic_grid64_128_naive_gnn', 'folder_log': 'results_cases/29.01_elliptic_grid64_128_naive_gnn', 'name': 'edbpd1', 'model_use': 'inference', 'save_model': False, 'cg_maxiter': 500, 'cg_atol': 1e-12, 'data_config': {'data_dir': '/mnt/local/data/vtrifonov/prec-learning-Notay-loss/', 'pde': 'poisson', 'grid': 128, 'variance': 0.5, 'lhs_type': 'fd', 'N_samples_train': nan, 'N_samples_test': 200, 'fill_factor': nan, 'threshold': nan}, 'model_config': {'layer_type': 'ConstantConv1d', 'node_enc': {'features': [1, 16, 16], 'N_layers': 2}, 'edge_enc': {'features': [1, 16, 16], 'N_layers': 2}, 'edge_dec': {'features': [16, 16, 1], 'N_layers': 2}, 'mp': {'edge_upd': {'features': [48, 16, 16], 'N_layers': 2}, 'node_upd': {'features': [32, 16, 16], 'N_layers': 2}, 'mp_rounds': 5, 'aggregate_edges': 'sum'}}, 'train_config': {'model_type': 'naive_gnn', 'loss_type': nan, 'batch_size': 8, 'optimizer': <function adam at 0x7f81d551e710>, 'lr': 0.001, 'optim_params': {}, 'epoch_num': 700}, 'seed': 42}.\n",
      "\n",
      "[INFO | root | 2025-01-31 00:27:08] - Data is loaded in 6.072e-01 sec.\n",
      "\n",
      "[INFO | root | 2025-01-31 00:27:08] - Model is trained in 5.428e-02 sec.\n",
      "[INFO | root | 2025-01-31 00:27:08] - PreCorrector's alpha = -.\n",
      "[INFO | root | 2025-01-31 00:27:08] - First and last losses: train = [nan, nan], test = [nan, nan].\n",
      "\n",
      "[WARNING | root | 2025-01-31 00:27:09] - /usr/local/lib/python3.10/dist-packages/jax/_src/lax/lax.py:2481: RuntimeWarning: invalid value encountered in cast\n",
      "  out = np.array(c).astype(eqn.params['new_dtype'])\n",
      "\n",
      "[WARNING | root | 2025-01-31 00:27:09] - /usr/local/lib/python3.10/dist-packages/jax/_src/lax/lax.py:2481: RuntimeWarning: invalid value encountered in cast\n",
      "  out = np.array(c).astype(eqn.params['new_dtype'])\n",
      "\n",
      "[WARNING | root | 2025-01-31 00:27:24] - /usr/local/lib/python3.10/dist-packages/jax/_src/lax/lax.py:2481: RuntimeWarning: invalid value encountered in cast\n",
      "  out = np.array(c).astype(eqn.params['new_dtype'])\n",
      "\n",
      "[INFO | root | 2025-01-31 00:27:29] - Precs are combined:\n",
      "[INFO | root | 2025-01-31 00:27:29] -  GNN prec construction time (sec) : mean = 1.050e-03, std = 2.719e-04.\n",
      "\n",
      "[INFO | root | 2025-01-31 00:30:18] - CG with GNN is finished:\n",
      "[INFO | root | 2025-01-31 00:30:18] -  iterations to atol([mean, std]): {0.001: [51.0, 0.0], 1e-06: [64.0, 0.0], 1e-09: [77.0, 0.0], 1e-12: [89.9, 0.25]};\n",
      "[INFO | root | 2025-01-31 00:30:18] -  time to atol([mean, std]): {0.001: [0.471, 0.05806], 1e-06: [0.5889, 0.06889], 1e-09: [0.7075, 0.08055], 1e-12: [0.8244, 0.08901]};\n",
      "[INFO | root | 2025-01-31 00:30:18] -  number of linsystems for which CG did not conerge to atol: {0.001: 0, 1e-06: 0, 1e-09: 0, 1e-12: 0}.\n",
      "\n",
      "[INFO | root | 2025-01-31 00:30:18] - [GNN precs] script `edbpd1` finished execution.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from experiments.script_gnn_prec import script_gnn_prec\n",
    "out = script_gnn_prec(config, return_meta_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97759c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "data/vtrifonov/prec-learning-Notay-loss/results_cases/29.01_elliptic_grid64_128_naive_gnn/edbpd1/edbpd1.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33e5bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d5aa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e219911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f029f045",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/mnt/local/data/vtrifonov/prec-learning-Notay-loss/results_cases/29.01_elliptic_grid64_128_naive_gnn/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cce06b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(path, 'meta_data.csv'), index_col=0)\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f1120ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_use</th>\n",
       "      <th>cg_maxiter</th>\n",
       "      <th>cg_atol</th>\n",
       "      <th>seed</th>\n",
       "      <th>model_type</th>\n",
       "      <th>use_nodes</th>\n",
       "      <th>node_upd_mlp</th>\n",
       "      <th>static_diag</th>\n",
       "      <th>aggregate_edges</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>epoch_num</th>\n",
       "      <th>pde</th>\n",
       "      <th>grid</th>\n",
       "      <th>variance</th>\n",
       "      <th>lhs_type</th>\n",
       "      <th>N_samples_train</th>\n",
       "      <th>N_samples_test</th>\n",
       "      <th>fill_factor</th>\n",
       "      <th>threshold</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>alpha</th>\n",
       "      <th>time_data</th>\n",
       "      <th>time_train</th>\n",
       "      <th>iters_1e_3</th>\n",
       "      <th>iters_1e_6</th>\n",
       "      <th>iters_1e_9</th>\n",
       "      <th>iters_1e_12</th>\n",
       "      <th>time_1e_3</th>\n",
       "      <th>time_1e_6</th>\n",
       "      <th>time_1e_9</th>\n",
       "      <th>time_1e_12</th>\n",
       "      <th>nans_1e_3</th>\n",
       "      <th>nans_1e_6</th>\n",
       "      <th>nans_1e_9</th>\n",
       "      <th>nans_1e_12</th>\n",
       "      <th>t_gnn_prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7pac81</th>\n",
       "      <td>train</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1.000000e-12</td>\n",
       "      <td>42.0</td>\n",
       "      <td>naive_gnn</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>sum</td>\n",
       "      <td>low_freq_loss</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>700.0</td>\n",
       "      <td>div_k_grad</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>fd</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>119500.0</td>\n",
       "      <td>116500.0</td>\n",
       "      <td>-</td>\n",
       "      <td>1.1780</td>\n",
       "      <td>1142.0</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>[4.057e-04, 1.022e-04]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mfmse7</th>\n",
       "      <td>train</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1.000000e-12</td>\n",
       "      <td>42.0</td>\n",
       "      <td>naive_gnn</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>sum</td>\n",
       "      <td>low_freq_loss</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>700.0</td>\n",
       "      <td>div_k_grad</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>fd</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>7848.0</td>\n",
       "      <td>8201.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.5789</td>\n",
       "      <td>336.2</td>\n",
       "      <td>[429.0, 37.93]</td>\n",
       "      <td>[454.0, 0.00]</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>[0.5537, 0.0495]</td>\n",
       "      <td>[0.5831, 0.0000]</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>186.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>[4.142e-04, 1.276e-05]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qcdazh</th>\n",
       "      <td>train</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1.000000e-12</td>\n",
       "      <td>42.0</td>\n",
       "      <td>naive_gnn</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>sum</td>\n",
       "      <td>low_freq_loss</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>700.0</td>\n",
       "      <td>div_k_grad</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>fd</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>906.5</td>\n",
       "      <td>955.6</td>\n",
       "      <td>-</td>\n",
       "      <td>0.5767</td>\n",
       "      <td>335.2</td>\n",
       "      <td>[61.2, 5.85]</td>\n",
       "      <td>[79.9, 7.42]</td>\n",
       "      <td>[97.1, 9.22]</td>\n",
       "      <td>[114.0, 10.84]</td>\n",
       "      <td>[0.0803, 0.0076]</td>\n",
       "      <td>[0.1045, 0.0096]</td>\n",
       "      <td>[0.1268, 0.0119]</td>\n",
       "      <td>[0.1486, 0.0140]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[3.067e-04, 3.332e-05]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vwnk3q</th>\n",
       "      <td>train</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1.000000e-12</td>\n",
       "      <td>42.0</td>\n",
       "      <td>naive_gnn</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>sum</td>\n",
       "      <td>low_freq_loss</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>700.0</td>\n",
       "      <td>poisson</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>fd</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>234.0</td>\n",
       "      <td>236.9</td>\n",
       "      <td>-</td>\n",
       "      <td>0.1727</td>\n",
       "      <td>329.6</td>\n",
       "      <td>[22.0, 0.25]</td>\n",
       "      <td>[29.0, 0.00]</td>\n",
       "      <td>[35.0, 0.00]</td>\n",
       "      <td>[42.0, 0.00]</td>\n",
       "      <td>[0.0299, 0.0004]</td>\n",
       "      <td>[0.0392, 0.0003]</td>\n",
       "      <td>[0.0471, 0.0003]</td>\n",
       "      <td>[0.0563, 0.0003]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[3.065e-04, 3.141e-05]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wncg6l</th>\n",
       "      <td>train</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1.000000e-12</td>\n",
       "      <td>42.0</td>\n",
       "      <td>naive_gnn</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>sum</td>\n",
       "      <td>low_freq_loss</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>700.0</td>\n",
       "      <td>poisson</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>fd</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>-</td>\n",
       "      <td>1.0630</td>\n",
       "      <td>1139.0</td>\n",
       "      <td>[33.0, 0.00]</td>\n",
       "      <td>[43.0, 0.00]</td>\n",
       "      <td>[51.0, 0.00]</td>\n",
       "      <td>[60.0, 0.00]</td>\n",
       "      <td>[0.0733, 0.0008]</td>\n",
       "      <td>[0.0950, 0.0009]</td>\n",
       "      <td>[0.1124, 0.0009]</td>\n",
       "      <td>[0.1319, 0.0010]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[4.076e-04, 6.705e-05]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nyczlm</th>\n",
       "      <td>train</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1.000000e-12</td>\n",
       "      <td>42.0</td>\n",
       "      <td>naive_gnn</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>sum</td>\n",
       "      <td>low_freq_loss</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>700.0</td>\n",
       "      <td>poisson</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>fd</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>409500.0</td>\n",
       "      <td>388900.0</td>\n",
       "      <td>-</td>\n",
       "      <td>3.4060</td>\n",
       "      <td>4410.0</td>\n",
       "      <td>[112.6, 0.91]</td>\n",
       "      <td>[146.0, 0.00]</td>\n",
       "      <td>[167.8, 0.76]</td>\n",
       "      <td>[197.7, 0.46]</td>\n",
       "      <td>[1.2697, 0.5724]</td>\n",
       "      <td>[1.6480, 0.7315]</td>\n",
       "      <td>[1.8941, 0.8367]</td>\n",
       "      <td>[2.2208, 0.9694]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1.052e-03, 2.784e-04]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w4qlpz</th>\n",
       "      <td>train</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>1.000000e-12</td>\n",
       "      <td>42.0</td>\n",
       "      <td>naive_gnn</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>sum</td>\n",
       "      <td>low_freq_loss</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>700.0</td>\n",
       "      <td>poisson</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>fd</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>409500.0</td>\n",
       "      <td>388900.0</td>\n",
       "      <td>-</td>\n",
       "      <td>3.7490</td>\n",
       "      <td>4412.0</td>\n",
       "      <td>[112.6, 0.91]</td>\n",
       "      <td>[146.0, 0.00]</td>\n",
       "      <td>[167.8, 0.76]</td>\n",
       "      <td>[197.7, 0.46]</td>\n",
       "      <td>[0.8056, 0.1208]</td>\n",
       "      <td>[1.0438, 0.1576]</td>\n",
       "      <td>[1.1986, 0.1807]</td>\n",
       "      <td>[1.4112, 0.2122]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1.052e-03, 2.808e-04]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6mmfo8</th>\n",
       "      <td>train</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1.000000e-12</td>\n",
       "      <td>42.0</td>\n",
       "      <td>naive_gnn</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>sum</td>\n",
       "      <td>low_freq_loss</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>700.0</td>\n",
       "      <td>div_k_grad</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>fd</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>906.5</td>\n",
       "      <td>955.6</td>\n",
       "      <td>-</td>\n",
       "      <td>0.6603</td>\n",
       "      <td>336.7</td>\n",
       "      <td>[61.2, 5.85]</td>\n",
       "      <td>[79.9, 7.42]</td>\n",
       "      <td>[97.1, 9.22]</td>\n",
       "      <td>[114.0, 10.84]</td>\n",
       "      <td>[0.0812, 0.0077]</td>\n",
       "      <td>[0.1056, 0.0097]</td>\n",
       "      <td>[0.1281, 0.0121]</td>\n",
       "      <td>[0.1501, 0.0142]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[3.074e-04, 4.264e-05]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edbpd1</th>\n",
       "      <td>train</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1.000000e-12</td>\n",
       "      <td>42.0</td>\n",
       "      <td>naive_gnn</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>sum</td>\n",
       "      <td>low_freq_loss</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>poisson</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>fd</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4958.0</td>\n",
       "      <td>4954.0</td>\n",
       "      <td>-</td>\n",
       "      <td>3.3560</td>\n",
       "      <td>15720.0</td>\n",
       "      <td>[51.0, 0.00]</td>\n",
       "      <td>[64.0, 0.00]</td>\n",
       "      <td>[77.0, 0.00]</td>\n",
       "      <td>[89.9, 0.25]</td>\n",
       "      <td>[1.0226, 0.1246]</td>\n",
       "      <td>[1.2814, 0.1530]</td>\n",
       "      <td>[1.5368, 0.1749]</td>\n",
       "      <td>[1.7913, 0.1968]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1.056e-03, 2.497e-04]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model_use  cg_maxiter       cg_atol  seed model_type  use_nodes  \\\n",
       "7pac81     train       500.0  1.000000e-12  42.0  naive_gnn       True   \n",
       "mfmse7     train       500.0  1.000000e-12  42.0  naive_gnn       True   \n",
       "qcdazh     train       500.0  1.000000e-12  42.0  naive_gnn       True   \n",
       "vwnk3q     train       500.0  1.000000e-12  42.0  naive_gnn       True   \n",
       "wncg6l     train       500.0  1.000000e-12  42.0  naive_gnn       True   \n",
       "nyczlm     train       500.0  1.000000e-12  42.0  naive_gnn       True   \n",
       "w4qlpz     train      2500.0  1.000000e-12  42.0  naive_gnn       True   \n",
       "6mmfo8     train       500.0  1.000000e-12  42.0  naive_gnn       True   \n",
       "edbpd1     train       500.0  1.000000e-12  42.0  naive_gnn       True   \n",
       "\n",
       "        node_upd_mlp  static_diag aggregate_edges      loss_type  batch_size  \\\n",
       "7pac81          True         True             sum  low_freq_loss         8.0   \n",
       "mfmse7          True         True             sum  low_freq_loss         8.0   \n",
       "qcdazh          True         True             sum  low_freq_loss         8.0   \n",
       "vwnk3q          True         True             sum  low_freq_loss         8.0   \n",
       "wncg6l          True         True             sum  low_freq_loss         8.0   \n",
       "nyczlm          True         True             sum  low_freq_loss         8.0   \n",
       "w4qlpz          True         True             sum  low_freq_loss         8.0   \n",
       "6mmfo8          True         True             sum  low_freq_loss         8.0   \n",
       "edbpd1          True         True             sum  low_freq_loss         8.0   \n",
       "\n",
       "           lr  epoch_num         pde   grid  variance lhs_type  \\\n",
       "7pac81  0.001      700.0  div_k_grad   64.0       0.5       fd   \n",
       "mfmse7  0.001      700.0  div_k_grad   32.0       0.5       fd   \n",
       "qcdazh  0.001      700.0  div_k_grad   32.0       0.1       fd   \n",
       "vwnk3q  0.001      700.0     poisson   32.0       0.5       fd   \n",
       "wncg6l  0.001      700.0     poisson   64.0       0.5       fd   \n",
       "nyczlm  0.001      700.0     poisson  128.0       0.5       fd   \n",
       "w4qlpz  0.001      700.0     poisson  128.0       0.5       fd   \n",
       "6mmfo8  0.001      700.0  div_k_grad   32.0       0.1       fd   \n",
       "edbpd1  0.001     2500.0     poisson  128.0       0.5       fd   \n",
       "\n",
       "        N_samples_train  N_samples_test  fill_factor  threshold  train_loss  \\\n",
       "7pac81           1000.0           200.0          1.0     0.0001    119500.0   \n",
       "mfmse7           1000.0           200.0          1.0     0.0001      7848.0   \n",
       "qcdazh           1000.0           200.0          1.0     0.0001       906.5   \n",
       "vwnk3q           1000.0           200.0          1.0     0.0001       234.0   \n",
       "wncg6l           1000.0           200.0          1.0     0.0001      1110.0   \n",
       "nyczlm           1000.0           200.0          1.0     0.0001    409500.0   \n",
       "w4qlpz           1000.0           200.0          1.0     0.0001    409500.0   \n",
       "6mmfo8           1000.0           200.0          1.0     0.0001       906.5   \n",
       "edbpd1           1000.0           200.0          1.0     0.0001      4958.0   \n",
       "\n",
       "        test_loss alpha  time_data  time_train      iters_1e_3     iters_1e_6  \\\n",
       "7pac81   116500.0     -     1.1780      1142.0      [nan, nan]     [nan, nan]   \n",
       "mfmse7     8201.0     -     0.5789       336.2  [429.0, 37.93]  [454.0, 0.00]   \n",
       "qcdazh      955.6     -     0.5767       335.2    [61.2, 5.85]   [79.9, 7.42]   \n",
       "vwnk3q      236.9     -     0.1727       329.6    [22.0, 0.25]   [29.0, 0.00]   \n",
       "wncg6l     1110.0     -     1.0630      1139.0    [33.0, 0.00]   [43.0, 0.00]   \n",
       "nyczlm   388900.0     -     3.4060      4410.0   [112.6, 0.91]  [146.0, 0.00]   \n",
       "w4qlpz   388900.0     -     3.7490      4412.0   [112.6, 0.91]  [146.0, 0.00]   \n",
       "6mmfo8      955.6     -     0.6603       336.7    [61.2, 5.85]   [79.9, 7.42]   \n",
       "edbpd1     4954.0     -     3.3560     15720.0    [51.0, 0.00]   [64.0, 0.00]   \n",
       "\n",
       "           iters_1e_9     iters_1e_12         time_1e_3         time_1e_6  \\\n",
       "7pac81     [nan, nan]      [nan, nan]        [nan, nan]        [nan, nan]   \n",
       "mfmse7     [nan, nan]      [nan, nan]  [0.5537, 0.0495]  [0.5831, 0.0000]   \n",
       "qcdazh   [97.1, 9.22]  [114.0, 10.84]  [0.0803, 0.0076]  [0.1045, 0.0096]   \n",
       "vwnk3q   [35.0, 0.00]    [42.0, 0.00]  [0.0299, 0.0004]  [0.0392, 0.0003]   \n",
       "wncg6l   [51.0, 0.00]    [60.0, 0.00]  [0.0733, 0.0008]  [0.0950, 0.0009]   \n",
       "nyczlm  [167.8, 0.76]   [197.7, 0.46]  [1.2697, 0.5724]  [1.6480, 0.7315]   \n",
       "w4qlpz  [167.8, 0.76]   [197.7, 0.46]  [0.8056, 0.1208]  [1.0438, 0.1576]   \n",
       "6mmfo8   [97.1, 9.22]  [114.0, 10.84]  [0.0812, 0.0077]  [0.1056, 0.0097]   \n",
       "edbpd1   [77.0, 0.00]    [89.9, 0.25]  [1.0226, 0.1246]  [1.2814, 0.1530]   \n",
       "\n",
       "               time_1e_9        time_1e_12  nans_1e_3  nans_1e_6  nans_1e_9  \\\n",
       "7pac81        [nan, nan]        [nan, nan]      200.0      200.0      200.0   \n",
       "mfmse7        [nan, nan]        [nan, nan]      186.0      199.0      200.0   \n",
       "qcdazh  [0.1268, 0.0119]  [0.1486, 0.0140]        0.0        0.0        0.0   \n",
       "vwnk3q  [0.0471, 0.0003]  [0.0563, 0.0003]        0.0        0.0        0.0   \n",
       "wncg6l  [0.1124, 0.0009]  [0.1319, 0.0010]        0.0        0.0        0.0   \n",
       "nyczlm  [1.8941, 0.8367]  [2.2208, 0.9694]        0.0        0.0        0.0   \n",
       "w4qlpz  [1.1986, 0.1807]  [1.4112, 0.2122]        0.0        0.0        0.0   \n",
       "6mmfo8  [0.1281, 0.0121]  [0.1501, 0.0142]        0.0        0.0        0.0   \n",
       "edbpd1  [1.5368, 0.1749]  [1.7913, 0.1968]        0.0        0.0        0.0   \n",
       "\n",
       "        nans_1e_12              t_gnn_prec  \n",
       "7pac81       200.0  [4.057e-04, 1.022e-04]  \n",
       "mfmse7       200.0  [4.142e-04, 1.276e-05]  \n",
       "qcdazh         0.0  [3.067e-04, 3.332e-05]  \n",
       "vwnk3q         0.0  [3.065e-04, 3.141e-05]  \n",
       "wncg6l         0.0  [4.076e-04, 6.705e-05]  \n",
       "nyczlm         0.0  [1.052e-03, 2.784e-04]  \n",
       "w4qlpz         0.0  [1.052e-03, 2.808e-04]  \n",
       "6mmfo8         0.0  [3.074e-04, 4.264e-05]  \n",
       "edbpd1         0.0  [1.056e-03, 2.497e-04]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06970986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_use</th>\n",
       "      <th>cg_maxiter</th>\n",
       "      <th>cg_atol</th>\n",
       "      <th>seed</th>\n",
       "      <th>model_type</th>\n",
       "      <th>use_nodes</th>\n",
       "      <th>node_upd_mlp</th>\n",
       "      <th>static_diag</th>\n",
       "      <th>aggregate_edges</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>epoch_num</th>\n",
       "      <th>pde</th>\n",
       "      <th>grid</th>\n",
       "      <th>variance</th>\n",
       "      <th>lhs_type</th>\n",
       "      <th>N_samples_train</th>\n",
       "      <th>N_samples_test</th>\n",
       "      <th>fill_factor</th>\n",
       "      <th>threshold</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>alpha</th>\n",
       "      <th>time_data</th>\n",
       "      <th>time_train</th>\n",
       "      <th>iters_1e_3</th>\n",
       "      <th>iters_1e_6</th>\n",
       "      <th>iters_1e_9</th>\n",
       "      <th>iters_1e_12</th>\n",
       "      <th>time_1e_3</th>\n",
       "      <th>time_1e_6</th>\n",
       "      <th>time_1e_9</th>\n",
       "      <th>time_1e_12</th>\n",
       "      <th>nans_1e_3</th>\n",
       "      <th>nans_1e_6</th>\n",
       "      <th>nans_1e_9</th>\n",
       "      <th>nans_1e_12</th>\n",
       "      <th>t_gnn_prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>qcdazh</th>\n",
       "      <td>train</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1.000000e-12</td>\n",
       "      <td>42.0</td>\n",
       "      <td>naive_gnn</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>sum</td>\n",
       "      <td>low_freq_loss</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>700.0</td>\n",
       "      <td>div_k_grad</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>fd</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>906.5</td>\n",
       "      <td>955.6</td>\n",
       "      <td>-</td>\n",
       "      <td>0.5767</td>\n",
       "      <td>335.2</td>\n",
       "      <td>[61.2, 5.85]</td>\n",
       "      <td>[79.9, 7.42]</td>\n",
       "      <td>[97.1, 9.22]</td>\n",
       "      <td>[114.0, 10.84]</td>\n",
       "      <td>[0.0803, 0.0076]</td>\n",
       "      <td>[0.1045, 0.0096]</td>\n",
       "      <td>[0.1268, 0.0119]</td>\n",
       "      <td>[0.1486, 0.0140]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[3.067e-04, 3.332e-05]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model_use  cg_maxiter       cg_atol  seed model_type  use_nodes  \\\n",
       "qcdazh     train       500.0  1.000000e-12  42.0  naive_gnn       True   \n",
       "\n",
       "        node_upd_mlp  static_diag aggregate_edges      loss_type  batch_size  \\\n",
       "qcdazh          True         True             sum  low_freq_loss         8.0   \n",
       "\n",
       "           lr  epoch_num         pde  grid  variance lhs_type  \\\n",
       "qcdazh  0.001      700.0  div_k_grad  32.0       0.1       fd   \n",
       "\n",
       "        N_samples_train  N_samples_test  fill_factor  threshold  train_loss  \\\n",
       "qcdazh           1000.0           200.0          1.0     0.0001       906.5   \n",
       "\n",
       "        test_loss alpha  time_data  time_train    iters_1e_3    iters_1e_6  \\\n",
       "qcdazh      955.6     -     0.5767       335.2  [61.2, 5.85]  [79.9, 7.42]   \n",
       "\n",
       "          iters_1e_9     iters_1e_12         time_1e_3         time_1e_6  \\\n",
       "qcdazh  [97.1, 9.22]  [114.0, 10.84]  [0.0803, 0.0076]  [0.1045, 0.0096]   \n",
       "\n",
       "               time_1e_9        time_1e_12  nans_1e_3  nans_1e_6  nans_1e_9  \\\n",
       "qcdazh  [0.1268, 0.0119]  [0.1486, 0.0140]        0.0        0.0        0.0   \n",
       "\n",
       "        nans_1e_12              t_gnn_prec  \n",
       "qcdazh         0.0  [3.067e-04, 3.332e-05]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[['qcdazh'], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9eef8bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01479"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.00029*51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d8dddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "402c4db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_ = ['qcdazh', 'vwnk3q', 'wncg6l', 'nyczlm']\n",
    "ls_ = ['edbpd1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfa04aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ = glob.glob(os.path.join(path, '*/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30dfbe3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "f = np.load(os.path.join(path, ls_[i], 'losses_'+ls_[i]+'.npz'))\n",
    "plt.plot(range(len(f['train_loss'])), f['train_loss'], label='train')\n",
    "plt.plot(range(len(f['test_loss'])), f['test_loss'], label='test')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b19436",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a464cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
