{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9333cf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '1.'\n",
    "sys.path.append('/mnt/local/data/vtrifonov/prec-learning-Notay-loss/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ff1ce9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import random, vmap, clear_caches, jit\n",
    "import numpy as np\n",
    "\n",
    "import optax\n",
    "from equinox.nn import Conv1d\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from time import perf_counter\n",
    "\n",
    "from data.dataset import dataset_Krylov, dataset_FD\n",
    "from linsolve.cg import ConjGrad\n",
    "from linsolve.precond import llt_prec_trig_solve\n",
    "from model import MessagePassing, FullyConnectedNet, PrecNet, ConstantConv1d, MessagePassingWithDot\n",
    "\n",
    "from utils import params_count, asses_cond, iter_per_residual, batch_indices\n",
    "from data.utils import direc_graph_from_linear_system_sparse\n",
    "from train import train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fa5eb6",
   "metadata": {},
   "source": [
    "# Setup experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c686ced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'simple'                # 'krylov', 'simple'\n",
    "grid = 32\n",
    "N_samples_train = 100\n",
    "N_samples_test = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa49e447",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhs_train = rhs_test = [5, 5, 2]           # 'random', 'laplace', [5, 5, 2]\n",
    "k_train = k_test = [5, 5, 2]           # 'random', 'poisson', [5, 5, 2]\n",
    "rhs_offset_train = rhs_offset_test = 0\n",
    "k_offset_train = k_offset_test = 10\n",
    "lhs_type = 'fd'                        # 'fd', 'ilu0', 'ilu1', 'ilu2'\n",
    "\n",
    "cg_repeats = 100\n",
    "if dataset == 'simple': cg_repeats = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bc13dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_ = ConstantConv1d         # 'ConstantConv1d' to make a \"zero\" NN initialization; 'Conv1d' to make a random initialization\n",
    "loss_type = 'llt'               # 'llt', 'llt-norm', 'notay', 'llt-res', 'llt-res-norm'\n",
    "\n",
    "# loss_reduction = jnp.mean\n",
    "loss_reduction = jnp.mean if loss_type == 'notay' else jnp.sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd884428",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    'node_enc': {\n",
    "        'features': [1, 16, 16],\n",
    "        'N_layers': 2,\n",
    "        'layer_': layer_\n",
    "    },\n",
    "    'edge_enc': {\n",
    "        'features': [1, 16, 16],\n",
    "        'N_layers': 2,\n",
    "        'layer_': layer_\n",
    "    },\n",
    "    'edge_dec': {\n",
    "        'features': [16, 16, 1],\n",
    "        'N_layers': 2,\n",
    "        'layer_': layer_\n",
    "    },\n",
    "    'mp': {\n",
    "        'edge_upd': {\n",
    "            'features': [48, 16, 16],\n",
    "            'N_layers': 2,\n",
    "            'layer_': layer_\n",
    "        },\n",
    "        'node_upd': {\n",
    "            'features': [32, 16, 16],\n",
    "            'N_layers': 2,\n",
    "            'layer_': layer_\n",
    "        },\n",
    "        'mp_rounds': 5\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8009c9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epoch_num = 1000\n",
    "lr = 1e-3\n",
    "schedule_params = None    # [start, stop, step, decay_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e3ef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (loss_type in {'notay', 'llt-res', 'llt-res-norm'} and dataset == 'simple') or (loss_type in {'llt', 'llt-norm'} and dataset == 'krylov'):\n",
    "    raise ValueError('Not valid dataset for a chosen loss')\n",
    "    \n",
    "if schedule_params != None:\n",
    "    assert len(schedule_params) == 4\n",
    "    \n",
    "    start, stop, step, decay_size = schedule_params\n",
    "    steps_per_batch = N_samples_train * cg_repeats // batch_size\n",
    "    start, stop, step = start*steps_per_batch, stop*steps_per_batch, step*steps_per_batch\n",
    "    lr = optax.piecewise_constant_schedule(\n",
    "        lr,\n",
    "        {k: v for k, v in zip(np.arange(start, stop, step), [decay_size, ] * len(jnp.arange(start, stop, step)))}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6fbece",
   "metadata": {},
   "source": [
    "# Make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a47c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = perf_counter()\n",
    "if dataset == 'krylov':\n",
    "    A_train, A_pad_train, b_train, u_exact_train, bi_edges_train, res_train, u_app_train = dataset_Krylov(grid, N_samples_train, seed=42, rhs_distr=rhs_train, rhs_offset=rhs_offset_train,\n",
    "                                                                                             k_distr=k_train, k_offset=k_offset_train, cg_repeats=cg_repeats, lhs_type=lhs_type)\n",
    "    A_test, A_pad_test, b_test, u_exact_test, bi_edges_test, res_test, u_app_test = dataset_Krylov(grid, N_samples_test, seed=43, rhs_distr=rhs_test, rhs_offset=rhs_offset_test,\n",
    "                                                                                       k_distr=k_test, k_offset=k_offset_test, cg_repeats=cg_repeats, lhs_type=lhs_type)\n",
    "elif dataset == 'simple':\n",
    "    A_train, A_pad_train, b_train, u_exact_train, bi_edges_train = dataset_FD(grid, N_samples_train, seed=42, rhs_distr=rhs_train, rhs_offset=rhs_offset_train,\n",
    "                                                                 k_distr=k_train, k_offset=k_offset_train, lhs_type=lhs_type)\n",
    "    A_test, A_pad_test, b_test, u_exact_test, bi_edges_test = dataset_FD(grid, N_samples_test, seed=43, rhs_distr=rhs_test, rhs_offset=rhs_offset_test,\n",
    "                                                             k_distr=k_test, k_offset=k_offset_test, lhs_type=lhs_type)\n",
    "print(perf_counter() - s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d811316d",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1285a694",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "NodeEncoder = FullyConnectedNet(**model_config['node_enc'], key=random.PRNGKey(seed))\n",
    "EdgeEncoder = FullyConnectedNet(**model_config['edge_enc'], key=random.PRNGKey(seed))\n",
    "EdgeDecoder = FullyConnectedNet(**model_config['edge_dec'], key=random.PRNGKey(seed))\n",
    "\n",
    "mp_rounds = 5\n",
    "MessagePass = MessagePassing(\n",
    "    update_edge_fn = FullyConnectedNet(**model_config['mp']['edge_upd'], key=random.PRNGKey(seed)),    \n",
    "    update_node_fn = FullyConnectedNet(**model_config['mp']['node_upd'], key=random.PRNGKey(seed)),\n",
    "    mp_rounds=model_config['mp']['mp_rounds']\n",
    ")\n",
    "\n",
    "model = PrecNet(NodeEncoder=NodeEncoder, EdgeEncoder=EdgeEncoder, \n",
    "                EdgeDecoder=EdgeDecoder, MessagePass=MessagePass)\n",
    "print(f'Parameter number: {params_count(model)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd9a2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = (X_train, X_test, y_train, y_test)\n",
    "if dataset == 'krylov':\n",
    "    data = (\n",
    "        [A_train, A_pad_train, b_train, bi_edges_train, u_exact_train, res_train, u_app_train],\n",
    "        [A_test, A_pad_test, b_test, bi_edges_test, u_exact_test, res_test, u_app_test],\n",
    "        jnp.array([1]), jnp.array([1])\n",
    "    )\n",
    "elif dataset == 'simple':\n",
    "    data = (\n",
    "        [A_train, A_pad_train, b_train, bi_edges_train, u_exact_train],\n",
    "        [A_test, A_pad_test, b_test, bi_edges_test, u_exact_test],\n",
    "        jnp.array([1]), jnp.array([1])\n",
    "    )\n",
    "train_config = {\n",
    "    'optimizer': optax.adam,\n",
    "    'lr': lr,\n",
    "    'optim_params': {},#{'weight_decay': 1e-8}, \n",
    "    'epoch_num': epoch_num,\n",
    "    'batch_size': batch_size,\n",
    "    'loss_reduction': loss_reduction\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08619a1e",
   "metadata": {},
   "source": [
    "### Pre-train with $LL^T$ loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12bca51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 4\n",
    "# lr = 1e-2\n",
    "\n",
    "# # steps_per_batch = N_samples_train // batch_size\n",
    "# # start, stop, step = 20*steps_per_batch, 101*steps_per_batch, 20*steps_per_batch\n",
    "# # decay_size = 1e-1\n",
    "# # lr = optax.piecewise_constant_schedule(\n",
    "# #     lr,\n",
    "# # #     {k: v for k, v in zip([37], [1e-1])}\n",
    "# #     {k: v for k, v in zip(np.arange(start, stop, step), [decay_size, ] * len(jnp.arange(start, stop, step)))}\n",
    "# # )\n",
    "# pretrain_train_config = {\n",
    "#     'optimizer': optax.adam,\n",
    "#     'lr': lr,\n",
    "#     'optim_params': {},#{'weight_decay': 1e-8}, \n",
    "#     'epoch_num': 150,\n",
    "#     'batch_size': batch_size\n",
    "# }\n",
    "# model, losses_pre = train(model, data, pretrain_train_config, loss_name='llt', with_cond=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0969853a",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8502cefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = perf_counter()\n",
    "model, losses = train(model, data, train_config, loss_name=loss_type, repeat_step=cg_repeats)\n",
    "dt = perf_counter() - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24503547",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb27df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = vmap(model, in_axes=(0, 0, 0, 0, 0), out_axes=(0))(*direc_graph_from_linear_system_sparse(A_pad_test[::cg_repeats, ...], b_test[::cg_repeats, ...])[:-1], bi_edges_test[::cg_repeats, ...])\n",
    "del model, data, A_train, A_pad_train, b_train, u_exact_train, bi_edges_train, bi_edges_test\n",
    "if dataset == 'krylov': del res_train, res_test, u_app_train, u_app_test\n",
    "clear_caches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7812e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# No pre-train\n",
    "axes[0].plot(range(len(losses[0])), losses[1], label='Test')\n",
    "axes[0].plot(range(len(losses[0])), losses[0], label='Train')\n",
    "\n",
    "# # With pre-train\n",
    "# axes[0].plot(range(len(losses_pre[0])), losses_pre[1], label='Test')\n",
    "# axes[0].plot(range(len(losses_pre[0])), losses_pre[0], label='Train')\n",
    "# axes[0].plot(range(len(losses_pre[0]), len(losses_pre[0])+len(losses[0])), losses[1], label='Test')\n",
    "# axes[0].plot(range(len(losses_pre[0]), len(losses_pre[0])+len(losses[0])), losses[0], label='Train')\n",
    "\n",
    "axes[0].legend()\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Notay loss');\n",
    "axes[0].grid();\n",
    "\n",
    "\n",
    "if True:\n",
    "    # No pre-train\n",
    "    axes[1].plot(range(len(losses[0])), losses[2], label='Test real cond P^(-1)A')\n",
    "\n",
    "    # With pre-train\n",
    "    # axes[1].plot(range(len(losses_pre[0])), losses_pre[2], label='Test')\n",
    "    # axes[1].plot(range(len(losses_pre[0]), len(losses_pre[0])+len(losses[0])), losses[2], label='Test')\n",
    "\n",
    "    axes[1].legend()\n",
    "    axes[1].set_yscale('log')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Condition number of $LL^T$')\n",
    "    axes[1].grid();\n",
    "\n",
    "\n",
    "# axes[0].axvline(pretrain_train_config['epoch_num'], 0, 1e11, linestyle='--', c='k')\n",
    "# axes[1].axvline(pretrain_train_config['epoch_num'], 0, 1e11, linestyle='--', c='k')\n",
    "# for vl in [28]:#[13, 17, 22, 25, 29, 39, 59, 79]:\n",
    "#     axes[0].axvline(vl, 0, 1e11, linestyle='--', c='k')\n",
    "#     axes[1].axvline(vl, 0, 1e11, linestyle='--', c='k')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "if True: \n",
    "    print(f'Final values\\n  train loss: {losses[0][-1]:.4f}\\n   test loss: {losses[1][-1]:.4f}\\n    LLT cond: {losses[2][-1]:.0f}')\n",
    "    print(f'\\nMinimim test loss `{jnp.min(losses[1]).item():.4f}` at epoch `{jnp.argmin(losses[1]).item():.0f}`')\n",
    "    print(f'\\nMinimim test P^(-1)A cond `{jnp.min(losses[2]).item():.0f}` at epoch `{jnp.argmin(losses[2]).item():.0f}`')\n",
    "else:\n",
    "    print(f'Final values\\n  train loss: {losses[0][-1]:.4f}\\n   test loss: {losses[1][-1]:.4f}')\n",
    "    print(f'\\nMinimim test loss `{jnp.min(losses[1]).item():.4f}` at epoch `{jnp.argmin(losses[1]).item():.0f}`')\n",
    "# if with_final_cond:\n",
    "#     cond_A, cond_LLT = jit(asses_cond)(A_test[::cg_repeats, ...], L)\n",
    "#     print(f'\\nTest lhs A cond: {cond_A:.0f}, test P^(-1)A cond: {cond_LLT:.0f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42da3dc4",
   "metadata": {},
   "source": [
    "# Apply model to CG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a99680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if dataset == 'krylov':\n",
    "#     A_test, _, b_test, _, _, _, _ = dataset_Krylov(grid, N_samples_test, seed=43, rhs_distr=rhs_test, rhs_offset=rhs_offset_test,\n",
    "#                                                                                        k_distr=k_test, k_offset=k_offset_test, cg_repeats=1, lhs_type='fd')\n",
    "# elif dataset == 'simple':\n",
    "#     A_test, _, b_test, _, _ = dataset_FD(grid, N_samples_test, seed=43, rhs_distr=rhs_test, rhs_offset=rhs_offset_test,\n",
    "#                                                              k_distr=k_test, k_offset=k_offset_test, lhs_type='fd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f2b6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not preconditioned\n",
    "X_I, R_I = ConjGrad(A_test[::cg_repeats, ...], b_test[::cg_repeats, ...], N_iter=300, prec_func=None, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec39abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prec = LL^T\n",
    "prec = partial(llt_prec_trig_solve, L=L)\n",
    "\n",
    "s_prec = perf_counter()\n",
    "X_LLT, R_LLT = ConjGrad(A_test[::cg_repeats, ...], b_test[::cg_repeats, ...], N_iter=300, prec_func=prec, seed=42)\n",
    "print(perf_counter() - s_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314f29e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(R_I.shape[-1]), jnp.linalg.norm(R_I, axis=1).mean(0), label=\"Not preconditioned\")\n",
    "plt.plot(range(R_LLT.shape[-1]), jnp.linalg.norm(R_LLT, axis=1).mean(0), label=\"Notay loss\")\n",
    "\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Norm residual')\n",
    "plt.legend();\n",
    "plt.yscale('log')\n",
    "plt.grid();\n",
    "\n",
    "# plt.ylim([1e-15, 1e0]);\n",
    "# plt.vlines([10, 20], [1e-15]*2, [100]*2, linestyle='--', color='k')\n",
    "\n",
    "res_I_dict = iter_per_residual(R_I)\n",
    "res_LLT_dict = iter_per_residual(R_LLT)\n",
    "print('        Simple CG:', res_I_dict)\n",
    "print('Preconditioned CG:', res_LLT_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb656d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 3, figsize=(14, 14))\n",
    "\n",
    "axes[0].imshow(X_I[0, :, -1].reshape([grid]*2))\n",
    "axes[1].imshow(X_LLT[0, :, -1].reshape([grid]*2))\n",
    "axes[2].imshow(u_exact_test[0, :].reshape([grid]*2))\n",
    "\n",
    "axes[0].set_title('No prec')\n",
    "axes[1].set_title('Notay-loss prec')\n",
    "axes[2].set_title('Exact solution')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c49fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6232ceaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
