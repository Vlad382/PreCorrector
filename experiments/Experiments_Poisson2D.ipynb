{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af213b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''\n",
    "os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '1.'\n",
    "sys.path.append('/mnt/local/data/vtrifonov/prec-learning-Notay-loss/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5084fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import random, vmap, clear_caches, jit\n",
    "import numpy as np\n",
    "\n",
    "import optax\n",
    "from equinox.nn import Conv1d\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from time import perf_counter\n",
    "\n",
    "from data.dataset import dataset_Krylov, dataset_FD\n",
    "from linsolve.cg import ConjGrad\n",
    "from linsolve.precond import llt_prec\n",
    "from model import MessagePassing, FullyConnectedNet, PrecNet, ConstantConv1d, MessagePassingWithDot\n",
    "\n",
    "from utils import params_count, asses_cond, iter_per_residual, batch_indices\n",
    "from data.utils import direc_graph_from_linear_system_sparse\n",
    "from train import train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fcc663",
   "metadata": {},
   "source": [
    "# Setup experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "05625cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'simple'                # 'krylov', 'simple'\n",
    "grid = 8\n",
    "N_samples_train = 30\n",
    "N_samples_test = 5\n",
    "\n",
    "rhs_train = rhs_test = 'random'           # 'random', 'laplace', [5, 5, 2]\n",
    "k_train = k_test = 'poisson'           # 'random', 'poisson', [5, 5, 2]\n",
    "rhs_offset_train = rhs_offset_test = 0\n",
    "k_offset_train = k_offset_test = 10\n",
    "lhs_type = 'ilu2'\n",
    "\n",
    "cg_repeats = 300\n",
    "if dataset == 'simple': cg_repeats = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "f38ca6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_ = ConstantConv1d         # 'ConstantConv1d' to make a \"zero\" NN initialization; 'Conv1d' to make a random initialization\n",
    "loss_type = 'notay'               # Either 'llt' or 'notay'\n",
    "with_cond = True               # If True will calculate cond during training. Extremly bad scaling (materialization of matrix)\n",
    "with_final_cond = False         # If True will calculate cond with final L. Also bad scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "ef21e3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "lr = 5e-4\n",
    "epoch_num = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "dade1a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment and setup to make steps in learning rate\n",
    "\n",
    "# steps_per_batch = N_samples_train * cg_repeats // batch_size\n",
    "# start, stop, step = 45*steps_per_batch, 101*steps_per_batch, 45*steps_per_batch\n",
    "# decay_size = 1e-1\n",
    "# lr = optax.piecewise_constant_schedule(\n",
    "#     lr,\n",
    "# #     {k: v for k, v in zip([37], [1e-1])}\n",
    "#     {k: v for k, v in zip(np.arange(start, stop, step), [decay_size, ] * len(jnp.arange(start, stop, step)))}\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e5df7a",
   "metadata": {},
   "source": [
    "# Make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "de56d839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.195051997026894\n"
     ]
    }
   ],
   "source": [
    "s1 = perf_counter()\n",
    "if dataset == 'krylov':\n",
    "    A_train, b_train, u_exact_train, bi_edges_train, res_train, u_app_train = dataset_Krylov(grid, N_samples_train, seed=42, rhs_distr=rhs_train, rhs_offset=rhs_offset_train,\n",
    "                                                                                             k_distr=k_train, k_offset=k_offset_train, cg_repeats=cg_repeats, lhs_type=lhs_type)\n",
    "    A_test, b_test, u_exact_test, bi_edges_test, res_test, u_app_test = dataset_Krylov(grid, N_samples_test, seed=43, rhs_distr=rhs_test, rhs_offset=rhs_offset_test,\n",
    "                                                                                       k_distr=k_test, k_offset=k_offset_test, cg_repeats=cg_repeats, lhs_type=lhs_type)\n",
    "elif dataset == 'simple':\n",
    "    A_train, b_train, u_exact_train, bi_edges_train = dataset_FD(grid, N_samples_train, seed=42, rhs_distr=rhs_train, rhs_offset=rhs_offset_train,\n",
    "                                                                 k_distr=k_train, k_offset=k_offset_train, lhs_type=lhs_type)\n",
    "    A_test, b_test, u_exact_test, bi_edges_test = dataset_FD(grid, N_samples_test, seed=43, rhs_distr=rhs_test, rhs_offset=rhs_offset_test,\n",
    "                                                             k_distr=k_test, k_offset=k_offset_test, lhs_type=lhs_type)\n",
    "print(perf_counter() - s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "53f3956b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 624) (30, 624) (30, 624)\n",
      "(344,) (344,) (344,)\n",
      "0 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Array([5.0625000e+00, 1.0000000e-15, 5.0625000e+00, 1.0000000e-15,\n",
       "       5.0625000e+00, 1.0000000e-15, 5.0625000e+00, 1.0000000e-15,\n",
       "       5.0625000e+00, 1.0000000e-15, 5.0625000e+00, 1.0000000e-15,\n",
       "       5.0625000e+00, 1.0000000e-15, 5.0625000e+00, 1.0000000e-15,\n",
       "       3.1640625e-01, 1.0000000e-15, 1.8518518e-31, 5.0625000e+00,\n",
       "       1.0000000e-15, 3.3750001e-01, 1.0000000e-15, 1.8436214e-31,\n",
       "       1.0000000e-15, 5.0625000e+00, 1.0000000e-15, 3.3900669e-01,\n",
       "       1.0000000e-15, 1.8430335e-31, 1.8518518e-31, 1.0000000e-15,\n",
       "       5.0625000e+00, 1.0000000e-15, 3.3911484e-01, 1.0000000e-15,\n",
       "       1.8429913e-31, 1.8436214e-31, 1.0000000e-15, 5.0625000e+00,\n",
       "       1.0000000e-15, 3.3912259e-01, 1.0000000e-15, 1.8429882e-31,\n",
       "       1.8430335e-31, 1.0000000e-15, 5.0625000e+00, 1.0000000e-15,\n",
       "       3.3912316e-01, 1.0000000e-15, 1.8429913e-31, 1.0000000e-15,\n",
       "       5.0625000e+00, 1.0000000e-15, 3.3912319e-01, 1.8429882e-31,\n",
       "       1.0000000e-15, 5.0625000e+00, 1.0000000e-15, 1.8429881e-31,\n",
       "       1.0000000e-15, 5.0625000e+00, 1.0000000e-15, 3.3750001e-01,\n",
       "       1.0000000e-15, 1.6265941e-31, 5.0625000e+00, 1.0000000e-15,\n",
       "       3.6508414e-01, 1.0000000e-15, 1.6183593e-31, 1.0000000e-15,\n",
       "       5.0625000e+00, 1.0000000e-15, 3.6752093e-01, 1.0000000e-15,\n",
       "       1.6176321e-31, 1.8684978e-31, 1.0000000e-15, 5.0625000e+00,\n",
       "       1.0000000e-15, 3.6773565e-01, 1.0000000e-15, 1.6175680e-31,\n",
       "       1.8590839e-31, 1.0000000e-15, 5.0625000e+00, 1.0000000e-15,\n",
       "       3.6775446e-01, 1.0000000e-15, 1.7336982e-31, 1.8582519e-31,\n",
       "       1.0000000e-15, 5.0625000e+00, 1.0000000e-15, 3.6775610e-01,\n",
       "       1.0000000e-15, 1.8581786e-31, 1.0000000e-15, 5.0625000e+00,\n",
       "       1.0000000e-15, 3.6775622e-01, 1.8581721e-31, 1.0000000e-15,\n",
       "       5.0625000e+00, 1.0000000e-15, 1.8408246e-31, 1.0000000e-15,\n",
       "       5.0625000e+00, 1.0000000e-15, 3.3900669e-01, 1.0000000e-15,\n",
       "       1.6066721e-31, 5.0625000e+00, 1.0000000e-15, 3.6752093e-01,\n",
       "       1.0000000e-15, 1.5983588e-31, 1.0000000e-15, 5.0625000e+00,\n",
       "       1.0000000e-15, 3.7014955e-01, 1.0000000e-15, 1.5975930e-31,\n",
       "       1.8709614e-31, 1.0000000e-15, 5.0625000e+00, 1.0000000e-15,\n",
       "       3.7039292e-01, 1.0000000e-15, 1.5987090e-31, 1.8613746e-31,\n",
       "       1.0000000e-15, 5.0625000e+00, 1.0000000e-15, 3.7041536e-01,\n",
       "       1.0000000e-15, 1.7251285e-31, 1.8604910e-31, 1.0000000e-15,\n",
       "       5.0625000e+00, 1.0000000e-15, 3.7041742e-01, 1.0000000e-15,\n",
       "       1.8604092e-31, 1.0000000e-15, 5.0625000e+00, 1.0000000e-15,\n",
       "       3.7041762e-01, 1.8602640e-31, 1.0000000e-15, 5.0625000e+00,\n",
       "       1.0000000e-15, 1.8405657e-31, 1.0000000e-15, 5.0625000e+00,\n",
       "       1.0000000e-15, 3.3911484e-01, 1.0000000e-15, 1.6047239e-31,\n",
       "       5.0625000e+00, 1.0000000e-15, 3.6773565e-01, 1.0000000e-15,\n",
       "       1.5963949e-31, 1.0000000e-15, 5.0625000e+00, 1.0000000e-15,\n",
       "       3.7039292e-01, 1.0000000e-15, 1.5956317e-31, 1.8712167e-31,\n",
       "       1.0000000e-15, 5.0625000e+00, 1.0000000e-15, 3.7064150e-01,\n",
       "       1.0000000e-15, 1.5969193e-31, 1.8616119e-31, 1.0000000e-15,\n",
       "       5.0625000e+00, 1.0000000e-15, 3.7066475e-01, 1.0000000e-15,\n",
       "       1.7243401e-31, 1.8607207e-31, 1.0000000e-15, 5.0625000e+00,\n",
       "       1.0000000e-15, 3.7066692e-01, 1.0000000e-15, 1.8606363e-31,\n",
       "       1.0000000e-15, 5.0625000e+00, 1.0000000e-15, 3.7066713e-01,\n",
       "       1.8604684e-31, 1.0000000e-15, 5.0625000e+00, 1.0000000e-15,\n",
       "       1.8405410e-31, 1.0000000e-15, 5.0625000e+00, 1.0000000e-15,\n",
       "       3.3912259e-01, 1.0000000e-15, 1.6045407e-31, 5.0625000e+00,\n",
       "       1.0000000e-15, 3.6775446e-01, 1.0000000e-15, 1.5962093e-31,\n",
       "       1.0000000e-15, 5.0625000e+00, 1.0000000e-15, 3.7041536e-01,\n",
       "       1.0000000e-15, 1.5954466e-31, 1.8712411e-31, 1.0000000e-15,\n",
       "       5.0625000e+00, 1.0000000e-15, 3.7066475e-01, 1.0000000e-15,\n",
       "       1.5967513e-31, 1.8616348e-31, 1.0000000e-15, 5.0625000e+00,\n",
       "       1.0000000e-15, 3.7068814e-01, 1.0000000e-15, 1.7242662e-31,\n",
       "       1.8607427e-31, 1.0000000e-15, 5.0625000e+00, 1.0000000e-15,\n",
       "       3.7069032e-01, 1.0000000e-15, 1.8606578e-31, 1.0000000e-15,\n",
       "       5.0625000e+00, 1.0000000e-15, 3.7069052e-01, 1.8604877e-31,\n",
       "       1.0000000e-15, 5.0625000e+00, 1.0000000e-15, 1.8405386e-31,\n",
       "       1.0000000e-15, 5.0625000e+00, 1.0000000e-15, 3.3912316e-01,\n",
       "       1.0000000e-15, 1.6045237e-31, 5.0625000e+00, 1.0000000e-15,\n",
       "       3.6775610e-01, 1.0000000e-15, 1.5961920e-31, 1.0000000e-15,\n",
       "       5.0625000e+00, 1.0000000e-15, 3.7041742e-01, 1.0000000e-15,\n",
       "       1.5954292e-31, 1.8712434e-31, 1.0000000e-15, 5.0625000e+00,\n",
       "       1.0000000e-15, 3.7066692e-01, 1.0000000e-15, 1.5967356e-31,\n",
       "       1.8616370e-31, 1.0000000e-15, 5.0625000e+00, 1.0000000e-15,\n",
       "       3.7069032e-01, 1.0000000e-15, 1.7242593e-31, 1.8607447e-31,\n",
       "       1.0000000e-15, 5.0625000e+00, 1.0000000e-15, 3.7069252e-01,\n",
       "       1.0000000e-15, 1.8606599e-31, 1.0000000e-15, 5.0625000e+00,\n",
       "       1.0000000e-15, 3.7069273e-01, 1.8604896e-31, 1.0000000e-15,\n",
       "       5.0625000e+00, 1.0000000e-15, 1.8405384e-31, 1.0000000e-15,\n",
       "       5.0625000e+00, 1.0000000e-15, 3.3912319e-01, 1.0000000e-15,\n",
       "       1.6045222e-31, 5.0625000e+00, 1.0000000e-15, 3.6775622e-01,\n",
       "       1.0000000e-15, 1.5961904e-31, 1.0000000e-15, 5.0625000e+00,\n",
       "       1.0000000e-15, 3.7041762e-01, 1.0000000e-15, 1.5954276e-31,\n",
       "       1.8712436e-31, 1.0000000e-15, 5.0625000e+00, 1.0000000e-15,\n",
       "       3.7066713e-01, 1.0000000e-15, 1.5967340e-31, 1.8616372e-31,\n",
       "       1.0000000e-15, 5.0625000e+00, 1.0000000e-15, 3.7069052e-01,\n",
       "       1.0000000e-15, 1.7242586e-31, 1.8607449e-31, 1.0000000e-15,\n",
       "       5.0625000e+00, 1.0000000e-15, 3.7069273e-01, 1.0000000e-15,\n",
       "       1.8606600e-31, 1.0000000e-15, 5.0625000e+00, 1.0000000e-15,\n",
       "       3.7069294e-01, 1.8604897e-31, 1.0000000e-15, 5.0625000e+00,\n",
       "       1.0000000e-15, 1.8405384e-31, 1.0000000e-15, 5.0625000e+00],      dtype=float32)"
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data.utils import direc_graph_from_linear_system_sparse, graph_tril, graph_to_low_tri_mat_sparse\n",
    "from jax.experimental import sparse as jsparse \n",
    "\n",
    "A_train = jsparse.bcoo_sort_indices(A_train)\n",
    "\n",
    "nodes, edges, receivers, senders, _ = direc_graph_from_linear_system_sparse(A_train, b_train)\n",
    "print(edges.shape, receivers.shape, senders.shape)\n",
    "nodes, edges, receivers, senders = nodes[0, ...][None, ...], edges[0, ...], receivers[0, ...], senders[0, ...]\n",
    "nodes, edges, receivers, senders = graph_tril(nodes, edges, receivers, senders)\n",
    "print(edges.shape, receivers.shape, senders.shape)\n",
    "\n",
    "# abc_tril = vmap(graph_to_low_tri_mat_sparse, in_axes=(0, 0, 0, 0), out_axes=(0))(nodes[None, ...], edges[None, ...], receivers[None, ...], senders[None, ...])\n",
    "abc_tril = graph_to_low_tri_mat_sparse(nodes, edges, receivers, senders)\n",
    "# abc_tril.data = abc_tril.data * 0 + 1\n",
    "for i in range(1):\n",
    "#     abc_tril.data = abc_tril.data * 0 + 1\n",
    "#     abc_tril.data = abc_tril.data.at[i].set(.5)\n",
    "    plt.imshow(abc_tril.todense())\n",
    "    print(senders[i], receivers[i])\n",
    "    plt.show();\n",
    "abc_tril.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9425b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f1eebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f637f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "id": "f2e78d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "\n",
    "@partial(jit, static_argnums=(2))\n",
    "def jspsolve_triangular_efficient(A, b, lower):\n",
    "    '''A must be a lower/upper triangular matrix.\n",
    "       It should be \"valid\": not singular (have no zeros on diagonal, no empty rows, etc.)'''\n",
    "    A = A.sort_indices()\n",
    "    Aval, bval = A.data, b\n",
    "    Arows, Acols = A.indices[:, 0], A.indices[:, 1]\n",
    "    x = jnp.zeros_like(bval)    \n",
    "    \n",
    "    diag_edge_indx = jnp.diff(jnp.hstack([Arows[:, None], Acols[:, None]]))\n",
    "    diag_edge_indx = jnp.where(diag_edge_indx == 0, 1, 0)\n",
    "    diag_edge_indx = jnp.nonzero(diag_edge_indx, size=nodes.shape[1], fill_value=jnp.nan)[0].astype(jnp.int32)\n",
    "\n",
    "    if lower:\n",
    "        xs_ = jnp.hstack([\n",
    "            jnp.arange(x.shape[0])[:, None],\n",
    "            diag_edge_indx[:, None]\n",
    "        ])\n",
    "    else:\n",
    "        xs_ = jnp.hstack([\n",
    "            jnp.arange(x.shape[0]-1, -1, -1)[:, None],\n",
    "            diag_edge_indx[::-1][:, None]\n",
    "        ])\n",
    "\n",
    "#     for i, diag_ind in xs_:\n",
    "#         row_ind = jnp.where(Arows == i, 1, 0)\n",
    "#         x_i = x.at[jnp.where(row_ind, Acols, Acols.shape[0])].get(mode='fill', fill_value=0)\n",
    "#         A_i = Aval.at[jnp.where(Arows == i, jnp.arange(Aval.shape[0]), Arows.shape[0])].get(mode='fill', fill_value=0)\n",
    "        \n",
    "#         c = jnp.sum(A_i * x_i)\n",
    "#         x = x.at[i].set(bval[i] - c)\n",
    "#         x = x.at[i].divide(Aval[diag_ind] + 1e-9)\n",
    "    def f_(carry, k):\n",
    "        i, diag_ind = k\n",
    "        Aval_, Arows_, Acols_, bval_, x_ = carry\n",
    "        row_ind = jnp.where(Arows_ == i, 1, 0)\n",
    "        \n",
    "        x_i = x_.at[jnp.where(row_ind, Acols_, Acols_.shape[0])].get(mode='fill', fill_value=0)\n",
    "        A_i = Aval_.at[jnp.where(Arows_ == i, jnp.arange(Aval_.shape[0]), Arows_.shape[0])].get(mode='fill', fill_value=0)\n",
    "\n",
    "        c = jnp.sum(A_i * x_i)\n",
    "        x_ = x_.at[i].set(bval_[i] - c)\n",
    "        x_ = x_.at[i].divide(Aval_[diag_ind] + 1e-9)\n",
    "        return (Aval_, Arows_, Acols_, bval_, x_), None\n",
    "    \n",
    "    carry_ = (Aval, Arows, Acols, bval, x)\n",
    "    (_, _, _, _, x), _ = jax.lax.scan(f_, carry_, xs_)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "9efe5490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "       -2.9802322e-08,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -1.4901161e-08,\n",
       "        0.0000000e+00,  0.0000000e+00,  1.4901161e-08,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -5.9604645e-08,\n",
       "        2.9802322e-08,  0.0000000e+00, -7.4505806e-09,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        2.9802322e-08,  0.0000000e+00, -5.9604645e-08,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.1920929e-07,\n",
       "        0.0000000e+00,  1.4901161e-08,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  2.9802322e-08,  0.0000000e+00,  2.9802322e-08,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  7.4505806e-09, -2.9802322e-08,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],      dtype=float32)"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn = jsparse.sparsify(lambda A: A.T)(abc_tril)#.todense()\n",
    "l_ = False\n",
    "arr = abc_tril if l_ else bn\n",
    "\n",
    "x1 = jspsolve_triangular_efficient(arr, b_train[0, :], lower=l_)\n",
    "# display(x1)\n",
    "nodes[0, :] - arr @ x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "078fa258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse.linalg import spsolve_triangular\n",
    "from scipy.sparse import csr_matrix\n",
    "bbb_ = csr_matrix(np.asarray(arr.todense()))\n",
    "x2 = spsolve_triangular(bbb_, np.asarray(b_train[0, :]), lower=l_)\n",
    "# display(x2)\n",
    "nodes[0, :] - bbb_ @ x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "2a82879b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(1.4901161e-08, dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(344, 344)"
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(jnp.abs(x1-x2).max())\n",
    "bbb_.nnz, abc_tril.nse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "98b2815a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4901161e-08\n",
      "--------------\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "7.450581e-09\n",
      "1.8626451e-09\n",
      "7.450581e-09\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "3.7252903e-09\n",
      "0.0\n",
      "0.0\n",
      "1.8626451e-09\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "7.450581e-09\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.4901161e-08\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "4.656613e-10\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "3.7252903e-09\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.4901161e-08\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(jnp.abs(x1 - x2).max(), end='\\n--------------\\n')\n",
    "for x_i in jnp.abs(x1 - x2):\n",
    "    print(x_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c16ce83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5a08ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e042f1a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f23fc3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c657b5cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92bd2396",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f87cd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "NodeEncoder = FullyConnectedNet(features=[1, 16, 16], N_layers=2, key=random.PRNGKey(seed), layer_=layer_)\n",
    "EdgeEncoder = FullyConnectedNet(features=[1, 16, 16], N_layers=2, key=random.PRNGKey(seed), layer_=layer_)\n",
    "EdgeDecoder = FullyConnectedNet(features=[16, 16, 1], N_layers=2, key=random.PRNGKey(seed), layer_=layer_)\n",
    "\n",
    "mp_rounds = 5\n",
    "MessagePass = MessagePassing(\n",
    "    update_edge_fn = FullyConnectedNet(features=[48, 16, 16], N_layers=2, key=random.PRNGKey(seed), layer_=layer_),    \n",
    "    update_node_fn = FullyConnectedNet(features=[32, 16, 16], N_layers=2, key=random.PRNGKey(seed), layer_=layer_),\n",
    "    mp_rounds=mp_rounds\n",
    ")\n",
    "\n",
    "model = PrecNet(NodeEncoder=NodeEncoder, EdgeEncoder=EdgeEncoder, \n",
    "                EdgeDecoder=EdgeDecoder, MessagePass=MessagePass)\n",
    "print(f'Parameter number: {params_count(model)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14633d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = (X_train, X_test, y_train, y_test)\n",
    "if dataset == 'krylov':\n",
    "    data = (\n",
    "        [A_train, b_train, bi_edges_train, u_exact_train, res_train, u_app_train],\n",
    "        [A_test, b_test, bi_edges_test, u_exact_test, res_test, u_app_test],\n",
    "        jnp.array([1]), jnp.array([1])\n",
    "    )\n",
    "elif dataset == 'simple':\n",
    "    data = (\n",
    "        [A_train, b_train, bi_edges_train, u_exact_train],\n",
    "        [A_test, b_test, bi_edges_test, u_exact_test],\n",
    "        jnp.array([1]), jnp.array([1])\n",
    "    )\n",
    "train_config = {\n",
    "    'optimizer': optax.adam,\n",
    "    'lr': lr,\n",
    "    'optim_params': {},#{'weight_decay': 1e-8}, \n",
    "    'epoch_num': epoch_num,\n",
    "    'batch_size': batch_size\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658ea7f5",
   "metadata": {},
   "source": [
    "### Pre-train with $LL^T$ loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c7ab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 4\n",
    "# lr = 1e-2\n",
    "\n",
    "# # steps_per_batch = N_samples_train // batch_size\n",
    "# # start, stop, step = 20*steps_per_batch, 101*steps_per_batch, 20*steps_per_batch\n",
    "# # decay_size = 1e-1\n",
    "# # lr = optax.piecewise_constant_schedule(\n",
    "# #     lr,\n",
    "# # #     {k: v for k, v in zip([37], [1e-1])}\n",
    "# #     {k: v for k, v in zip(np.arange(start, stop, step), [decay_size, ] * len(jnp.arange(start, stop, step)))}\n",
    "# # )\n",
    "# pretrain_train_config = {\n",
    "#     'optimizer': optax.adam,\n",
    "#     'lr': lr,\n",
    "#     'optim_params': {},#{'weight_decay': 1e-8}, \n",
    "#     'epoch_num': 150,\n",
    "#     'batch_size': batch_size\n",
    "# }\n",
    "# model, losses_pre = train(model, data, pretrain_train_config, loss_name='llt', with_cond=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9236d02",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeea857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = perf_counter()\n",
    "model, losses = train(model, data, train_config, loss_name=loss_type, with_cond=with_cond, repeat_step=cg_repeats)\n",
    "dt = perf_counter() - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69356c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b67a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = vmap(model, in_axes=(0, 0, 0, 0, 0), out_axes=(0))(*direc_graph_from_linear_system_sparse(A_test[::cg_repeats, ...], b_test[::cg_repeats, ...])[:-1], bi_edges_test[::cg_repeats, ...])\n",
    "del model, data, A_train, b_train, u_exact_train, bi_edges_train\n",
    "if dataset == 'krylov': del res_train, res_test, u_app_train, u_app_test\n",
    "clear_caches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1765cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# No pre-train\n",
    "axes[0].plot(range(len(losses[0])), losses[1], label='Test')\n",
    "axes[0].plot(range(len(losses[0])), losses[0], label='Train')\n",
    "\n",
    "# # With pre-train\n",
    "# axes[0].plot(range(len(losses_pre[0])), losses_pre[1], label='Test')\n",
    "# axes[0].plot(range(len(losses_pre[0])), losses_pre[0], label='Train')\n",
    "# axes[0].plot(range(len(losses_pre[0]), len(losses_pre[0])+len(losses[0])), losses[1], label='Test')\n",
    "# axes[0].plot(range(len(losses_pre[0]), len(losses_pre[0])+len(losses[0])), losses[0], label='Train')\n",
    "\n",
    "axes[0].legend()\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Notay loss');\n",
    "axes[0].grid();\n",
    "\n",
    "\n",
    "if with_cond:\n",
    "    # No pre-train\n",
    "    axes[1].plot(range(len(losses[0])), losses[2], label='Test real cond P^(-1)A')\n",
    "\n",
    "    # With pre-train\n",
    "    # axes[1].plot(range(len(losses_pre[0])), losses_pre[2], label='Test')\n",
    "    # axes[1].plot(range(len(losses_pre[0]), len(losses_pre[0])+len(losses[0])), losses[2], label='Test')\n",
    "\n",
    "    axes[1].legend()\n",
    "    axes[1].set_yscale('log')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Condition number of $LL^T$')\n",
    "    axes[1].grid();\n",
    "\n",
    "\n",
    "# axes[0].axvline(pretrain_train_config['epoch_num'], 0, 1e11, linestyle='--', c='k')\n",
    "# axes[1].axvline(pretrain_train_config['epoch_num'], 0, 1e11, linestyle='--', c='k')\n",
    "# for vl in [28]:#[13, 17, 22, 25, 29, 39, 59, 79]:\n",
    "#     axes[0].axvline(vl, 0, 1e11, linestyle='--', c='k')\n",
    "#     axes[1].axvline(vl, 0, 1e11, linestyle='--', c='k')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "if with_cond: \n",
    "    print(f'Final values\\n  train loss: {losses[0][-1]:.4f}\\n   test loss: {losses[1][-1]:.4f}\\n    LLT cond: {losses[2][-1]:.0f}')\n",
    "    print(f'\\nMinimim test loss `{jnp.min(losses[1]).item():.4f}` at epoch `{jnp.argmin(losses[1]).item():.0f}`')\n",
    "    print(f'\\nMinimim test P^(-1)A cond `{jnp.min(losses[2]).item():.0f}` at epoch `{jnp.argmin(losses[2]).item():.0f}`')\n",
    "else:\n",
    "    print(f'Final values\\n  train loss: {losses[0][-1]:.4f}\\n   test loss: {losses[1][-1]:.4f}')\n",
    "    print(f'\\nMinimim test loss `{jnp.min(losses[1]).item():.4f}` at epoch `{jnp.argmin(losses[1]).item():.0f}`')\n",
    "if with_final_cond:\n",
    "    cond_A, cond_LLT = jit(asses_cond)(A_test[::cg_repeats, ...], L)\n",
    "    print(f'\\nTest lhs A cond: {cond_A:.0f}, test P^(-1)A cond: {cond_LLT:.0f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2829e879",
   "metadata": {},
   "source": [
    "# Apply model to CG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19fd279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not preconditioned\n",
    "X_I, R_I = ConjGrad(A_test[::cg_repeats, ...], b_test[::cg_repeats, ...], N_iter=300, prec_func=None, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7705e8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prec = LL^T\n",
    "prec = partial(llt_prec, L=L)\n",
    "\n",
    "X_LLT, R_LLT = ConjGrad(A_test[::cg_repeats, ...], b_test[::cg_repeats, ...], N_iter=300, prec_func=prec, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e159f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(R_I.shape[-1]), jnp.linalg.norm(R_I, axis=1).mean(0), label=\"Not preconditioned\")\n",
    "plt.plot(range(R_LLT.shape[-1]), jnp.linalg.norm(R_LLT, axis=1).mean(0), label=\"Notay loss\")\n",
    "\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Norm residual')\n",
    "plt.legend();\n",
    "plt.yscale('log')\n",
    "plt.grid();\n",
    "\n",
    "# plt.ylim([1e-15, 1e0]);\n",
    "# plt.vlines([10, 20], [1e-15]*2, [100]*2, linestyle='--', color='k')\n",
    "\n",
    "res_I_dict = iter_per_residual(R_I)\n",
    "res_LLT_dict = iter_per_residual(R_LLT)\n",
    "print('        Simple CG:', res_I_dict)\n",
    "print('Preconditioned CG:', res_LLT_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce93baf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 3, figsize=(14, 14))\n",
    "\n",
    "axes[0].imshow(X_I[0, :, -1].reshape([grid]*2))\n",
    "axes[1].imshow(X_LLT[0, :, -1].reshape([grid]*2))\n",
    "axes[2].imshow(u_exact_test[0, :].reshape([grid]*2))\n",
    "\n",
    "axes[0].set_title('No prec')\n",
    "axes[1].set_title('Notay-loss prec')\n",
    "axes[2].set_title('Exact solution')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9ed79c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fe3f67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
