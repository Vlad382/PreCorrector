{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95cd0978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''\n",
    "os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '1.'\n",
    "sys.path.append('/mnt/local/data/vtrifonov/prec-learning-Notay-loss/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c5c9adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import random, vmap, clear_caches, jit\n",
    "import numpy as np\n",
    "\n",
    "import optax\n",
    "from equinox.nn import Conv1d\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from time import perf_counter\n",
    "\n",
    "from data.dataset import dataset_Krylov, dataset_FD\n",
    "from linsolve.cg import ConjGrad\n",
    "from linsolve.precond import llt_prec_trig_solve\n",
    "from model import MessagePassing, FullyConnectedNet, PrecNet, ConstantConv1d, MessagePassingWithDot\n",
    "\n",
    "from utils import params_count, asses_cond, iter_per_residual, batch_indices\n",
    "from data.utils import direc_graph_from_linear_system_sparse\n",
    "from train import train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ee2c13",
   "metadata": {},
   "source": [
    "# Setup experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd0d654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'krylov'                # 'krylov', 'simple'\n",
    "grid = 64\n",
    "N_samples_train = 30\n",
    "N_samples_test = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f86663e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhs_train = rhs_test = 'random'           # 'random', 'laplace', [5, 5, 2]\n",
    "k_train = k_test = 'poisson'           # 'random', 'poisson', [5, 5, 2]\n",
    "rhs_offset_train = rhs_offset_test = 0\n",
    "k_offset_train = k_offset_test = 10\n",
    "lhs_type = 'ilu2'                        # 'fd', 'ilu0', 'ilu1', 'ilu2'\n",
    "\n",
    "cg_repeats = 100\n",
    "if dataset == 'simple': cg_repeats = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d52f886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_ = ConstantConv1d         # 'ConstantConv1d' to make a \"zero\" NN initialization; 'Conv1d' to make a random initialization\n",
    "loss_type = 'llt-res-norm'               # 'llt', 'llt-norm', 'notay', 'llt-res', 'llt-res-norm'\n",
    "with_cond = True               # If True will calculate cond during training. Extremly bad scaling (materialization of matrix)\n",
    "# with_final_cond = False         # If True will calculate cond with final L. Also bad scaling\n",
    "\n",
    "loss_reduction = jnp.mean\n",
    "# loss_reduction = jnp.mean if loss_type == 'notay' else jnp.sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76b1b658",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (loss_type in {'notay', 'llt-res', 'llt-res-norm'} and dataset == 'simple') or (loss_type in {'llt', 'llt-norm'} and dataset == 'krylov'):\n",
    "    raise ValueError('Not valid dataset for a chosen loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dccf81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "lr = 1e-3\n",
    "epoch_num = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b8e1b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment and setup to make steps in learning rate\n",
    "\n",
    "# steps_per_batch = N_samples_train * cg_repeats // batch_size\n",
    "# start, stop, step = 45*steps_per_batch, 101*steps_per_batch, 45*steps_per_batch\n",
    "# decay_size = 1e-1\n",
    "# lr = optax.piecewise_constant_schedule(\n",
    "#     lr,\n",
    "# #     {k: v for k, v in zip([37], [1e-1])}\n",
    "#     {k: v for k, v in zip(np.arange(start, stop, step), [decay_size, ] * len(jnp.arange(start, stop, step)))}\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24166568",
   "metadata": {},
   "source": [
    "# Make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e067bbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA backend failed to initialize: jaxlib/cuda/versions_helpers.cc:98: operation cuInit(0) failed: CUDA_ERROR_NO_DEVICE (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.7735421359539\n"
     ]
    }
   ],
   "source": [
    "s1 = perf_counter()\n",
    "if dataset == 'krylov':\n",
    "    A_train, A_pad_train, b_train, u_exact_train, bi_edges_train, res_train, u_app_train = dataset_Krylov(grid, N_samples_train, seed=42, rhs_distr=rhs_train, rhs_offset=rhs_offset_train,\n",
    "                                                                                             k_distr=k_train, k_offset=k_offset_train, cg_repeats=cg_repeats, lhs_type=lhs_type)\n",
    "    A_test, A_pad_test, b_test, u_exact_test, bi_edges_test, res_test, u_app_test = dataset_Krylov(grid, N_samples_test, seed=43, rhs_distr=rhs_test, rhs_offset=rhs_offset_test,\n",
    "                                                                                       k_distr=k_test, k_offset=k_offset_test, cg_repeats=cg_repeats, lhs_type=lhs_type)\n",
    "elif dataset == 'simple':\n",
    "    A_train, A_pad_train, b_train, u_exact_train, bi_edges_train = dataset_FD(grid, N_samples_train, seed=42, rhs_distr=rhs_train, rhs_offset=rhs_offset_train,\n",
    "                                                                 k_distr=k_train, k_offset=k_offset_train, lhs_type=lhs_type)\n",
    "    A_test, A_pad_test, b_test, u_exact_test, bi_edges_test = dataset_FD(grid, N_samples_test, seed=43, rhs_distr=rhs_test, rhs_offset=rhs_offset_test,\n",
    "                                                             k_distr=k_test, k_offset=k_offset_test, lhs_type=lhs_type)\n",
    "print(perf_counter() - s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c2b2d8",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d5a9929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from jax import jit\n",
    "from jax.lax import scan, cond\n",
    "import jax.numpy as jnp\n",
    "\n",
    "@partial(jit, static_argnums=(2))\n",
    "def jspsolve_triangular(A, b, lower):\n",
    "    '''A must be a lower/upper triangular matrix.\n",
    "       It should be \"valid\": not singular (have no zeros on diagonal, no empty rows, etc.)'''\n",
    "    A = A.sort_indices()\n",
    "    Aval, bval = A.data, b\n",
    "    Arows, Acols = A.indices[:, 0], A.indices[:, 1]\n",
    "    x = jnp.zeros_like(bval)    \n",
    "\n",
    "    diag_edge_indx = jnp.diff(jnp.hstack([Arows[:, None], Acols[:, None]]))\n",
    "    diag_edge_indx = jnp.where(diag_edge_indx == 0, 1, 0)\n",
    "    diag_edge_indx = jnp.nonzero(diag_edge_indx, size=bval.shape[0], fill_value=jnp.nan)[0].astype(jnp.int32)\n",
    "\n",
    "    if lower:\n",
    "        xs_ = jnp.hstack([\n",
    "            jnp.arange(x.shape[0])[:, None],\n",
    "            diag_edge_indx[:, None]\n",
    "        ])\n",
    "    else:\n",
    "        xs_ = jnp.hstack([\n",
    "            jnp.arange(x.shape[0]-1, -1, -1)[:, None],\n",
    "            diag_edge_indx[::-1][:, None]\n",
    "        ])\n",
    "    def f_(carry, k):\n",
    "        i, diag_ind = k\n",
    "        Aval_, Arows_, Acols_, bval_, x_ = carry\n",
    "        \n",
    "#         x_i = x_.at[jnp.where(Arows_ == i, Acols_, Acols_.shape[0])].get(mode='fill', fill_value=0)\n",
    "#         x_i = lax.cond(cond, f_1, f_2, operand) -- should try\n",
    "        \n",
    "        x_i = vmap(cond, in_axes=(0, None, None, 0), out_axes=(0))(Arows_ == i, lambda j: x_[j], lambda j: 0., Acols_)\n",
    "        A_i = jnp.where(Arows_ == i, Aval_, 0)\n",
    "        \n",
    "        c = (bval_[i] - jnp.sum(A_i * x_i)) / (Aval_[diag_ind] + 1e-9)\n",
    "        x_ = x_.at[i].set(c)\n",
    "        return (Aval_, Arows_, Acols_, bval_, x_), None\n",
    "    \n",
    "    carry_ = (Aval, Arows, Acols, bval, x)\n",
    "    (_, _, _, _, x), _ = scan(f_, carry_, xs_)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5a3d4c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data.utils import direc_graph_from_linear_system_sparse, graph_tril, graph_to_low_tri_mat_sparse\n",
    "# from jax.experimental import sparse as jsparse \n",
    "\n",
    "# nodes, edges, receivers, senders, _ = direc_graph_from_linear_system_sparse(A_train, b_train)\n",
    "# print(edges.shape, receivers.shape, senders.shape)\n",
    "# nodes, edges, receivers, senders = nodes[0, ...][None, ...], edges[0, ...], receivers[0, ...], senders[0, ...]\n",
    "# nodes, edges, receivers, senders = graph_tril(nodes, edges, receivers, senders)\n",
    "# print(edges.shape, receivers.shape, senders.shape)\n",
    "\n",
    "# # abc_tril = vmap(graph_to_low_tri_mat_sparse, in_axes=(0, 0, 0, 0), out_axes=(0))(nodes[None, ...], edges[None, ...], receivers[None, ...], senders[None, ...])\n",
    "# abc_tril = graph_to_low_tri_mat_sparse(nodes, edges, receivers, senders)\n",
    "# # abc_tril.data = abc_tril.data * 0 + 1\n",
    "# plt.imshow(abc_tril.todense());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "58f4f4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array(2.3841858e-07, dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_caches()\n",
    "\n",
    "l_ = True\n",
    "arr = abc_tril if l_ else jsparse.sparsify(lambda A: A.T)(abc_tril)\n",
    "\n",
    "dt = 0\n",
    "for _ in range(100):\n",
    "    s_ = perf_counter()\n",
    "    x1 = jspsolve_triangular(arr, b_train[0, :], lower=l_)\n",
    "    dt += perf_counter() - s_\n",
    "\n",
    "# display(x1)\n",
    "print(f'time: {dt:.0f} sec')\n",
    "jnp.abs(nodes[0, :] - arr @ x1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7590f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0ae9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddf1d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
