{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a66f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "sys.path.append('/mnt/local/data/vtrifonov/prec-learning-Notay-loss/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c3c3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import random, vmap, clear_caches\n",
    "import numpy as np\n",
    "\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "\n",
    "from data import dataset_LLT\n",
    "from conj_grad import ConjGrad, apply_LLT\n",
    "from loss import Notay_loss\n",
    "from model import MessagePassingWithDiag, MessagePassingNoDiag, FullyConnectedNet\n",
    "from prec_models import PrecNetLearnAll, PrecNetCopyDiag, PrecNetCopyDiagSqrt, PrecNetRigidLDLT\n",
    "\n",
    "from utils import params_count, asses_cond, iter_per_residual\n",
    "from data import direc_graph_from_linear_system_sparse\n",
    "from train import train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc08324b",
   "metadata": {},
   "source": [
    "# Make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57156b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = 64\n",
    "N_samples_train = 32\n",
    "N_samples_test = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68224b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_train, b_train, u_exact_train, bi_edges_train = dataset_LLT(grid, N_samples_train, seed=42)\n",
    "A_test, b_test, u_exact_test, bi_edges_test = dataset_LLT(grid, N_samples_test, seed=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b1e611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize linear system in form: norm**(-1) * A @ u = f * norm**(-1)\n",
    "\n",
    "norm_train = jnp.linalg.norm(A_train.data, axis=1)\n",
    "norm_test = jnp.linalg.norm(A_test.data, axis=1)\n",
    "\n",
    "b_train = jnp.einsum('bi, b -> bi', b_train, 1./norm_train)\n",
    "A_train = A_train / norm_train[..., None, None]\n",
    "\n",
    "b_test = jnp.einsum('bi, b -> bi', b_test, 1./norm_test)\n",
    "A_test = A_test / norm_test[..., None, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fc2ebb",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309027ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "NodeEncoder = FullyConnectedNet(features=[1, 16, 16], N_layers=2, key=random.PRNGKey(seed))\n",
    "EdgeEncoder = FullyConnectedNet(features=[1, 16, 16], N_layers=2, key=random.PRNGKey(seed))\n",
    "EdgeDecoder = FullyConnectedNet(features=[16, 16, 1], N_layers=2, key=random.PRNGKey(seed))\n",
    "\n",
    "mp_rounds = 5\n",
    "MessagePass = MessagePassingNoDiag(\n",
    "    update_edge_fn = FullyConnectedNet(features=[48, 16, 16], N_layers=2, key=random.PRNGKey(seed)),    \n",
    "    update_node_fn = FullyConnectedNet(features=[48, 16, 16], N_layers=2, key=random.PRNGKey(seed)),\n",
    "    mp_rounds=mp_rounds\n",
    ")\n",
    "\n",
    "model = PrecNetCopyDiagSqrt(NodeEncoder=NodeEncoder, EdgeEncoder=EdgeEncoder, \n",
    "                EdgeDecoder=EdgeDecoder, MessagePass=MessagePass)\n",
    "print(f'Parameter number: {params_count(model)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97a6289",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "# start, stop, step = 5, 10, 20\n",
    "# decay_size = 1e+1\n",
    "# lr = optax.piecewise_constant_schedule(\n",
    "#     lr,\n",
    "#     {k: v for k, v in zip([10, 150], [1e-1, 15])}#zip(np.arange(start, stop, step), [decay_size, ] * len(jnp.arange(start, stop, step)))}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5af8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = (X_train, X_test, y_train, y_test)\n",
    "data = (\n",
    "    [A_train, b_train, bi_edges_train, u_exact_train],\n",
    "    [A_test, b_test, bi_edges_test, u_exact_test],\n",
    "    jnp.array([1]), jnp.array([1])\n",
    ")\n",
    "train_config = {\n",
    "    'optimizer': optax.adam,\n",
    "    'lr': lr,\n",
    "    'optim_params': {},#{'weight_decay': 1e-8}, \n",
    "    'epoch_num': 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b357b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, losses = train(model, data, train_config, loss_name='llt', with_cond=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6ca2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(range(len(losses[0])), losses[1], label='Test')\n",
    "axes[0].plot(range(len(losses[0])), losses[0], label='Train')\n",
    "axes[0].legend()\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('$\\|LL^Tx - b\\|_2^2$');\n",
    "axes[0].grid();\n",
    "\n",
    "axes[1].plot(range(len(losses[0])), losses[2], label='Test')\n",
    "axes[1].legend()\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Condition number of $LL^T$')\n",
    "axes[1].grid();\n",
    "\n",
    "# for vl in [129]:#[13, 17, 22, 25, 29, 39, 59, 79]:\n",
    "#     axes[0].axvline(vl, 0, 1e11, linestyle='--', c='k')\n",
    "#     axes[1].axvline(vl, 0, 1e11, linestyle='--', c='k')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "cond_A, cond_LLT = asses_cond(A_test, vmap(model, in_axes=(0, 0, 0, 0, 0), out_axes=(0))(*direc_graph_from_linear_system_sparse(A_test, b_test)[:-1], bi_edges_test))\n",
    "print(f'Final values\\n  train loss: {losses[0][-1]:.4f}\\n   test loss: {losses[1][-1]:.4f}\\n    LLT cond: {losses[2][-1]:.0f}')\n",
    "print(f'\\nMinimim test loss `{jnp.min(losses[1]).item():.4f}` at epoch `{jnp.argmin(losses[1]).item()+1:.0f}`')\n",
    "print(f'\\nMinimim test cond `{jnp.min(losses[2]).item():.0f}` at epoch `{jnp.argmin(losses[2]).item()+1:.0f}`')\n",
    "print(f'\\nTest lhs A cond: {cond_A:.0f}, test LLT cond: {cond_LLT:.0f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968d0b04",
   "metadata": {},
   "source": [
    "# Apply model to CG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc19dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data, A_train, b_train, u_exact_train, bi_edges_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a039a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not preconditioned\n",
    "X_I, R_I = ConjGrad(A_test, b_test, N_iter=300, prec_func=None, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d815839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prec = LL^T\n",
    "L = vmap(model, in_axes=(0, 0, 0, 0, 0), out_axes=(0))(*direc_graph_from_linear_system_sparse(A_test, b_test)[:-1], bi_edges_test)\n",
    "prec = partial(apply_LLT, L=L)\n",
    "\n",
    "X_LLT, R_LLT = ConjGrad(A_test, b_test, N_iter=300, prec_func=prec, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7017d998",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(R_I.shape[-1]), jnp.linalg.norm(R_I, axis=1).mean(0), label=\"Not preconditioned\")\n",
    "plt.plot(range(R_LLT.shape[-1]), jnp.linalg.norm(R_LLT, axis=1).mean(0), label=\"$\\|LL^Tx - b\\|_2^2$\")\n",
    "\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Norm residual')\n",
    "plt.legend();\n",
    "plt.yscale('log')\n",
    "plt.grid();\n",
    "\n",
    "# plt.ylim([1e-15, 1e0]);\n",
    "# plt.vlines(110, 1e-15, 1, linestyle='--', color='k')\n",
    "\n",
    "res_I_dict = iter_per_residual(R_I)\n",
    "res_LLT_dict = iter_per_residual(R_LLT)\n",
    "print('        Simple CG:', res_I_dict)\n",
    "print('Preconditioned CG:', res_LLT_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8768c48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 3, figsize=(14, 14))\n",
    "\n",
    "axes[0].imshow(X_I[0, :].reshape([grid]*2))\n",
    "axes[1].imshow(X_LLT[0, :].reshape([grid]*2))\n",
    "axes[2].imshow(u_exact_test[0, :].reshape([grid]*2))\n",
    "\n",
    "axes[0].set_title('No prec')\n",
    "axes[1].set_title('LLT-loss prec')\n",
    "axes[2].set_title('Exact solution')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105d8c58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
