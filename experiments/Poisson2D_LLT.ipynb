{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6de300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "sys.path.append('/mnt/local/data/vtrifonov/prec-learning-Notay-loss/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "354a92fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import random, vmap, clear_caches\n",
    "import numpy as np\n",
    "\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "\n",
    "from data import dataset_Poisson2D_finite_diff\n",
    "from conj_grad import ConjGrad, apply_LLT\n",
    "from model import MessagePassing, FullyConnectedNet, PrecNet\n",
    "\n",
    "from utils import params_count, asses_cond, iter_per_residual, batch_indices\n",
    "from data import direc_graph_from_linear_system_sparse\n",
    "from train import train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b531fb",
   "metadata": {},
   "source": [
    "# Make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eddcbb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = 128\n",
    "N_samples_train = 1\n",
    "N_samples_test = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb121c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-02 10:17:28.882005: W external/xla/xla/service/gpu/nvptx_compiler.cc:744] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.3.107). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "A_train, b_train, u_exact_train, bi_edges_train = dataset_Poisson2D_finite_diff(grid, N_samples_train, seed=42, rhs_distr=[5, 5, 2])\n",
    "A_test, b_test, u_exact_test, bi_edges_test = dataset_Poisson2D_finite_diff(grid, N_samples_test, seed=43, rhs_distr=[5, 5, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "478f3cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize linear system in form: norm**(-1) * A @ u = f * norm**(-1)\n",
    "\n",
    "norm_train = jnp.linalg.norm(A_train.data, axis=1)\n",
    "b_train = jnp.einsum('bi, b -> bi', b_train, 1./norm_train)\n",
    "A_train = A_train / norm_train[..., None, None]\n",
    "\n",
    "norm_test = jnp.linalg.norm(A_test.data, axis=1)\n",
    "b_test_norm = jnp.einsum('bi, b -> bi', b_test, 1./norm_test)\n",
    "A_test_norm = A_test / norm_test[..., None, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3429a8",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da809806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter number: 2753\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "NodeEncoder = FullyConnectedNet(features=[1, 16, 16], N_layers=2, key=random.PRNGKey(seed))\n",
    "EdgeEncoder = FullyConnectedNet(features=[1, 16, 16], N_layers=2, key=random.PRNGKey(seed))\n",
    "EdgeDecoder = FullyConnectedNet(features=[16, 16, 1], N_layers=2, key=random.PRNGKey(seed))\n",
    "\n",
    "mp_rounds = 5\n",
    "MessagePass = MessagePassing(\n",
    "    update_edge_fn = FullyConnectedNet(features=[48, 16, 16], N_layers=2, key=random.PRNGKey(seed)),    \n",
    "    update_node_fn = FullyConnectedNet(features=[32, 16, 16], N_layers=2, key=random.PRNGKey(seed)),\n",
    "    mp_rounds=mp_rounds\n",
    ")\n",
    "\n",
    "model = PrecNet(NodeEncoder=NodeEncoder, EdgeEncoder=EdgeEncoder, \n",
    "                EdgeDecoder=EdgeDecoder, MessagePass=MessagePass)\n",
    "print(f'Parameter number: {params_count(model)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab88dc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "lr = 1e-3\n",
    "\n",
    "# steps_per_batch = N_samples_train // batch_size\n",
    "# start, stop, step = 100*steps_per_batch, 201*steps_per_batch, 100*steps_per_batch\n",
    "# decay_size = 1e-1\n",
    "# lr = optax.piecewise_constant_schedule(\n",
    "#     lr,\n",
    "# #     {k: v for k, v in zip([10, 150], [1e-1, 15])}\n",
    "#     {k: v for k, v in zip(np.arange(start, stop, step), [decay_size, ] * len(jnp.arange(start, stop, step)))}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b92dfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = (X_train, X_test, y_train, y_test)\n",
    "data = (\n",
    "    [A_train, b_train, bi_edges_train, u_exact_train],\n",
    "    [A_test_norm, b_test_norm, bi_edges_test, u_exact_test],\n",
    "    jnp.array([1]), jnp.array([1])\n",
    ")\n",
    "train_config = {\n",
    "    'optimizer': optax.adam,\n",
    "    'lr': lr,\n",
    "    'optim_params': {},#{'weight_decay': 1e-8}, \n",
    "    'epoch_num': 150,\n",
    "    'batch_size': batch_size\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de06047",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, losses = train(model, data, train_config, loss_name='llt', with_cond=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55ccdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = vmap(model, in_axes=(0, 0, 0, 0, 0), out_axes=(0))(*direc_graph_from_linear_system_sparse(A_test_norm, b_test_norm)[:-1], bi_edges_test)\n",
    "del data, A_test_norm, b_test_norm, A_train, b_train, u_exact_train, bi_edges_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c85164",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(range(len(losses[0])), losses[1], label='Test')\n",
    "axes[0].plot(range(len(losses[0])), losses[0], label='Train')\n",
    "axes[0].legend()\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('$\\|LL^Tx - b\\|_2^2$');\n",
    "axes[0].grid();\n",
    "\n",
    "axes[1].plot(range(len(losses[0])), losses[2], label='Test')\n",
    "axes[1].legend()\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Condition number of $LL^T$')\n",
    "axes[1].grid();\n",
    "W\n",
    "# for vl in [129]:#[13, 17, 22, 25, 29, 39, 59, 79]:\n",
    "#     axes[0].axvline(vl, 0, 1e11, linestyle='--', c='k')\n",
    "#     axes[1].axvline(vl, 0, 1e11, linestyle='--', c='k')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "cond_A, cond_LLT = asses_cond(A_test, L)\n",
    "print(f'Final values\\n  train loss: {losses[0][-1]:.4f}\\n   test loss: {losses[1][-1]:.4f}')#\\n    LLT cond: {losses[2][-1]:.0f}')\n",
    "print(f'\\nMinimim test loss `{jnp.min(losses[1]).item():.4f}` at epoch `{jnp.argmin(losses[1]).item():.0f}`')\n",
    "print(f'\\nMinimim test cond `{jnp.min(losses[2]).item():.0f}` at epoch `{jnp.argmin(losses[2]).item():.0f}`')\n",
    "print(f'\\nTest lhs A cond: {cond_A:.0f}, test LLT cond: {cond_LLT:.0f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aad163",
   "metadata": {},
   "source": [
    "# Apply model to CG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b1e5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not preconditioned\n",
    "X_I, R_I = ConjGrad(A_test, b_test, N_iter=300, prec_func=None, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed4af41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prec = LL^T\n",
    "prec = partial(apply_LLT, L=L)\n",
    "\n",
    "X_LLT, R_LLT = ConjGrad(A_test, b_test, N_iter=300, prec_func=prec, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eec030",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(R_I.shape[-1]), jnp.linalg.norm(R_I, axis=1).mean(0), label=\"Not preconditioned\")\n",
    "plt.plot(range(R_LLT.shape[-1]), jnp.linalg.norm(R_LLT, axis=1).mean(0), label=\"$\\|LL^Tx - b\\|_2^2$\")\n",
    "\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Norm residual')\n",
    "plt.legend();\n",
    "plt.yscale('log')\n",
    "plt.grid();\n",
    "\n",
    "# plt.ylim([1e-15, 1e0]);\n",
    "# plt.vlines(110, 1e-15, 1, linestyle='--', color='k')\n",
    "\n",
    "res_I_dict = iter_per_residual(R_I)\n",
    "res_LLT_dict = iter_per_residual(R_LLT)\n",
    "print('        Simple CG:', res_I_dict)\n",
    "print('Preconditioned CG:', res_LLT_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddc1a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 3, figsize=(14, 14))\n",
    "\n",
    "axes[0].imshow(X_I[0, :].reshape([grid]*2))\n",
    "axes[1].imshow(X_LLT[0, :].reshape([grid]*2))\n",
    "axes[2].imshow(u_exact_test[0, :].reshape([grid]*2))\n",
    "\n",
    "axes[0].set_title('No prec')\n",
    "axes[1].set_title('LLT-loss prec')\n",
    "axes[2].set_title('Exact solution')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1f4fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.abs(b_test[0, ...] - A_test[0, ...].todense() @ u_exact_test[0, ...]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e086a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
